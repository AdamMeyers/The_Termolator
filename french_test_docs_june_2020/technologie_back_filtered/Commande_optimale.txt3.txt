Commande optimale 
La théorie de la commande optimale permet de déterminer la commande d'un système qui minimise (ou maximise) un critère de performance, éventuellement sous des contraintes. Le cas le plus classique (et le plus simple) est celui de contraintes de type inégalité sur la commande, mais on peut aussi envisager des contraintes de même type sur l'état. Cette théorie est une généralisation du calcul des variations. Elle comporte deux volets : le principe du maximum (ou du minimum) dû à Lev Pontriaguine et à ses collaborateurs du Steklov Institute de Moscou, et l'équation de Hamilton-Jacobi-Bellman, généralisation de l'équation de Hamilton-Jacobi, et conséquence directe de la programmation dynamique initiée aux États-Unis par Richard Bellman. La théorie de la commande optimale fait partie de l'automatique et des mathématiques appliquées (optimisation des processus). En tant que cette théorie généralise le calcul des variations, elle a également un champ d'application en physique mathématique, et les développements théoriques actuels rejoignent les mathématiques pures. 
Les idées sous-jacentes au principe du maximum et à la programmation dynamique sont fort anciennes et ont été intimement liées dès leur préhistoire. Elles ont été développées de manière indépendante et pratiquement simultanée, vers le milieu des années 1950, et elles continuent aujourd’hui d’avoir de nombreuses connexions. 
La programmation dynamique a pour origine le principe de Huygens pour la propagation de la lumière : c’est le fameux principe des « sources intermédiaires » qui interprète les phénomènes de réflexion et de réfraction en supposant la propagation d'ondelettes sphériques secondaires issues d'une onde sphérique principale ; le principe d'Huygens est lui-même fondé sur le principe de Fermat qui postule que la lumière suit le trajet dont le temps de propagation est minimal.  
Les travaux récents ont permis de généraliser ces deux approches sans les modifier profondément ; ils se sont pour une bonne part tournés vers l'affaiblissement des conditions de différentiabilité dans le cadre de l'« analyse non lisse » initiée par Frank H. Clarke, en utilisant les « gradients généralisés » (ou « différentielles généralisées ») introduits par cet auteur . Cela a conduit à envisager des commandes de nature plus générale que les fonctions continues par morceaux du théorème originel de Pontriaguine et ses collaborateurs : notamment des fonctions mesurables au sens de Lebesgue. Un autre type d'extension porte sur les systèmes à retard et plus généralement de dimension infinie. D'autre part, Boltyanskii a donné une « version faible » du principe du maximum pour les systèmes à temps discret après avoir développé à cette fin des techniques mathématiques spécifiques, mais on peut démontrer sans difficulté son résultat à partir des conditions de Karush, Kuhn et Tucker. Sous certaines conditions de convexité, on retrouve toutefois un véritable principe du maximum pour ce type de systèmes. 
Par nature, le principe du maximum de Pontriaguine est une condition nécessaire d’optimalité, tandis que la programmation dynamique fournit une condition suffisante. D’autre part, le principe du maximum donne comme solution une commande en boucle ouverte (fonction du temps) alors que la programmation dynamique conduit à une commande en boucle fermée (fonction de l’état du système). 
Toutefois, la commande solution du principe du maximum peut, dans les cas favorables, être mise sous forme d’une commande en boucle fermée. Un des grands avantages du principe du maximum sur la programmation dynamique est une plus grande facilité de mise en œuvre, celle-ci, quand elle est appliquée aux systèmes à temps continu, impliquant la résolution d’une équation aux dérivées partielles (l’équation d'Hamilton-Jacobi-Bellman), tandis que celui-là se ramène à la résolution d’équations différentielles ordinaires (résolution qui est toutefois sérieusement compliquée par le fait que le problème est « aux deux bouts »). 
La programmation dynamique s'applique aussi bien aux systèmes déterministes qu'aux systèmes stochastiques, tandis que le principe du maximum ne s'applique (avec quelques exceptions) qu'aux systèmes déterministes. 
Nous considérons le problème de commande optimale sans contrainte sur l'état avec les hypothèses de différentiabilité habituelles (le problème, ou plutôt sa solution, se complique considérablement en cas de contrainte sur l'état, car un des multiplicateurs de Lagrange est alors une mesure qui n'est pas absolument continue par rapport à la mesure de Lebesgue). Pour simplifier les notations, nous considérons le cas où l'instant initial et l'état initial sont fixés. Soit le système :  
Soit le critère de performance 
On appelle pseudo-hamiltonien la fonction 
Enfin, nous appellerons condition de non trivialité l'inégalité 
On montre le résultat suivant : 
La démonstration de ce théorème (avec formula_7 de dimension finie) occupe près de 40 pages dans l'ouvrage de Pontriaguine et ses collaborateurs. Lorsque l'état final est astreint à appartenir à une sous-variété de formula_7 de codimension infinie, des variations en aiguille de la commande ne suffisent plus (elles ne donnent pas suffisamment de degrés de liberté) et un contre-exemple construit par Yu Vladimirovich Egorov en 1963 montre que le Principe du maximum est inexact. Il existe une extension du principe du maximum pour les systèmes semi-linéaires dont l'état est à valeurs dans un espace de Banach quelconque ; ce résultat est obtenu en utilisant des « variations diffuses » (« diffuse variations » ou « patch variations ») de la commande. 
Cette commande toujours égale (dans le cas où elle a une seule composante) à sa valeur minimale ou à sa valeur maximale, avec des commutations. Dans le cas de systèmes linéaires d'ordre 2, on peut trouver des solutions explicites fondées sur le portrait de phase. D'autre part, supposons le système linéaire stationnaire d'ordre formula_159 et commandable. Si les valeurs propres de la matrice d'état sont toutes réelles, le nombre de commutations est au plus égal à formula_160. Si ces valeurs propres sont toutes dans le demi-plan gauche et 0 appartient à l'intérieur de formula_12, la commande optimale existe et est unique. 
Supposons que le système soit "linéaire" et de dimension finie, soit 
D'après le principe général de la programmation dynamique, la commande optimale minimise sur formula_32, pour tout formula_174, le critère 
avec  
Désignons par formula_177 la valeur optimale de ce critère. En plus des hypothèses précédentes, nous supposons maintenant que les fonctions formula_178 et formula_179 sont continûment différentiables. Nous supposons également que formula_132 et supprimons cette variable des arguments de formula_181, qui est donc maintenant une fonction 
avec pour condition aux limites  
ce qui équivaut à l'équation de Hamilton-Jacobi-Bellman. La condition aux limites et la valeur optimale du critère découlent de la définition de formula_190. 
Démonstration de la condition suffisante d'optimalité : 
et en conséquence 
On déduit dans ce qui suit le théorème de Pontriaguine-Boltyansky du théorème de Bellman en supposant la fonction formula_211 deux fois continûment différentiable, bien que cette seconde hypothèse ne soit malheureusement pas satisfaite dans les cas les plus courants tels que celui de la commande Bang-Bang, où formula_212 n'est pas même différentiable sur les trajectoires optimales (cette hypothèse est satisfaite, néanmoins, dans le cas du Calcul des variations, lorsque le lagrangien formula_19 et la fonction "K" sont analytiques, le temps final est fixé et l'état final est libre, comme on le verra plus loin). 
Il vient alors nécessairement 
L'équation de Hamilton-Jacobi-Bellman implique le Principe du maximum 
ainsi que l'égalité 
On tire de cette dernière 
et on obtient finalement la seconde équation canonique 
car avec le plongement ci-dessus, et compte tenu du fait que la forme bilinéaire continue formula_228 est symétrique,  
sont deux écritures différentes de la même forme linéaire continue. 
Pour démontrer l'égalité formula_243 (en notation abrégée) sur les trajectoires optimales, supposons pour simplifier que formula_12 soit un ouvert d'un espace de Banach. Le Principe du maximum implique alors la condition d'Euler formula_245 à l'optimum. Par conséquent, 
Il reste à obtenir la condition de transversalité. Sur formula_248 on doit avoir formula_249. Par conséquent, pour tout accroissement admissible infiniment petit formula_250, 
La condition de transversalité est donc démontrée. 
Le problème du Calcul des variations consiste à minimiser un critère de la forme 
La condition de non trivialité implique formula_132, et nous supprimons donc désormais formula_263 des arguments de formula_185. Les équations canoniques se réduisent maintenant aux équations d'Hamilton habituelles. En remplaçant l'expression obtenue plus haut pour formula_265 dans la seconde équation canonique, on obtient la "condition d'Euler-Lagrange" : 
D'autre part, en supposant que formula_19 admet une différentielle partielle seconde par rapport à formula_268 et que cette différentielle partielle seconde est une fonction continue, le Principe du maximum implique, au second ordre, la "condition faible de Legendre" 
qui signifie que la forme bilinéaire continue symétrique formula_270 doit être semi-définie positive. Pour qu'en plus l'hamiltonien soit régulier, il faut que soit satisfaite la "condition forte de Legendre" 
qui signifie que cette forme bilinéaire symétrique doit être définie positive. 
Soit la fonction de Weierstrass, encore appelée l'« excessus » 
Le Principe du maximum implique la "condition de Weierstrass" formula_273 (obtenue avec des « variations fortes », analogues aux « variations en aiguille » introduites par Boltyanskii pour la démonstration du Principe du maximum). On écrit également la fonction de Weierstrass sous la forme 
La différence essentielle entre le Principe du maximum et la condition de Weierstrass est que, dans cette dernière, on a dès le début l'égalité formula_277, laquelle égalité, qui détermine formula_278 comme fonction implicite de formula_265, paraît essentielle dans le Calcul des variations classique (elle conduit à raisonner avec un hamiltonien plutôt qu'avec un pseudo-hamiltonien, comme on le verra plus loin). En s'affranchissant de cette condition, Weierstrass, ou d'autres avant lui, auraient pu formuler le Principe du maximum. 
La condition de Carathéodory peut s'exprimer sous la forme suivante : supposons qu'il existe une fonction continûment différentiable formula_280 telle que, en posant, comme on l'a déjà fait plus haut, 
Alors la fonction optimale formula_284 est solution de l'équation différentielle 
La maximisation de formula_181 par rapport à "u" est effectuée sur un ouvert. La maximisation du pseudo-hamiltonien implique donc la condition d'Euler 
Soit alors l'hamiltonien 
On obtient à partir de l'équation de Carathéodory l'équation d'Hamilton-Jacobi habituelle 
On a vu plus haut comment déduire le principe de Pontriaguine de l'équation d'Hamilton-Jacobi-Bellman en supposant formula_212 de classe formula_215. On déduit exactement de la même manière toutes les conditions nécessaires de minimum fort du Calcul des variations de la condition de Carathéodory en supposant "S" de classe formula_215.  
Depuis l'article publié par Kalman en 1960, la « commande linéaire quadratique » a fait l'objet de nombreuses investigations. Supposons que le système soit linéaire et de dimension finie, ayant pour équation d'état 
Appliquons maintenant la méthode de la programmation dynamique, de manière à obtenir une condition suffisante d'optimalité (qui, dans le cas considéré, sera également nécessaire ; et l'on pourrait également appliquer le Principe du maximum, qui conduirait au même résultat). Pour cela, choisissons une « fonction de Bellman » de la forme 
On a 
ce qui donne formula_335 L'équation d'Hamilton-Jacobi-Bellman s'écrit donc (en omettant la dépendance des différentes matrices par rapport au temps pour alléger les notations) 
ce qui conduit à choisir la fonction formula_337 solution de l'équation de Riccati matricielle 
avec la "condition finale" 
On notera que les deux conditions suivantes sont équivalentes : 
Supposons formula_356. La commande optimale est donc bien définie ; elle est linéaire et en boucle fermée, et donnée par 
Notons que la valeur optimale du critère est formula_359 
On a le résultat suivant: 
On considère parfois un critère quadratique plus général, comprenant un terme croisé, de la forme 
Soit un point matériel de masse au repos formula_372, placé dans un champ de force formula_373. Dans le cadre de la relativité restreinte, dans lequel on se place ici, l'action est donnée par 
La première équation canonique de Hamilton redonne formula_375 
La maximisation du pseudo-hamiltonien se fait sur l'ensemble formula_379. 