Text Encoding Initiative

La "" (abrégé en TEI, en français « initiative pour l’encodage du texte ») est une communauté académique internationale dans le champ des humanités numériques visant à définir des recommandations pour l’encodage de documents textuels. Depuis 1987, le modèle théorique s’est adapté à différentes technologies, d’abord sous la forme d’une DTD SGML, puis XML. Dans sa version P5 (2007), le schéma TEI est représenté dans plusieurs langages, et notamment, Relax NG. Le schéma TEI est un noyau autour duquel gravitent beaucoup d’activités coordonnées sous forme de comités démocratiques et internationaux pour, notamment, conduire la maintenance et la croissance du schéma, rédiger la documentation, développer des outils génériques, assurer le support sur des listes de diffusions et faire connaître le format.

Le projet TEI a commencé le 13 novembre 1987 aux environs de New York, à Poughkeepsie. Une conférence organisée avec un cofinancement de l’agence fédérale américaine pour la dotation des humanités ("") et de l’Union européenne a résulté en un texte définissant ses objectifs. Bien avant la fondation du W3C, un groupe se proposait de définir des recommandations pour l’encodage des textes informatiques. Après plus de trente ans, ces principes restent d’actualité pour décrire l’intention de la TEI, tant dans ses documents et son code, que son organisation. Le plus simple est de proposer une traduction de ces principes pour comprendre de quoi il s’agit.

Les recommandations visent à fournir un "format" standard pour favoriser l’échange de textes dans les humanités et à suggérer des "principes abstraits" pour l’encodage des textes. Elles doivent définir une syntaxe recommandée pour ce format, définir un métalangage pour la description des structures d’encodage de textes, puis décrire ce format et ces structures, à la fois dans ce métalangage et en langage naturel. Les recommandations doivent également proposer des ensembles de conventions d’encodage adaptés à plusieurs applications différentes. Notamment, il faut qu'elles incluent un ensemble minimal de conventions pour l’encodage de nouveaux textes. Les recommandations seront rédigées par plusieurs commissions coordonnées par un comité d’organisation représentant les principaux organismes impliqués (financièrement ou pas). On distinguera la documentation (métadonnées) des textes ('), la représentation des composants textuels ('), l’analyse et l’interprétation du texte (') et la définition du métalangage, ainsi que la description de structures textuelles proposées ou existantes ('). La compatibilité avec des standards existants sera maintenue le plus longtemps possible. Plusieurs grandes bibliothèques de textes sont d’accord sur le principe de soutenir les recommandations de la TEI dans leur fonction de format d’échange, encourageant tous les commanditaires à soutenir le développement d’outils pour faciliter cet échange. La conversion de textes numériques existants vers ce nouveau format implique la traduction de leurs conventions dans la syntaxe du nouveau format. Aucune information supplémentaire n'est exigée pour la conversion dans ce nouveau format.

La TEI est donc une organisation qui se réunit pour définir un format d’encodage. Dès l’origine sont distingués la "représentation" des composants textuels, qui ne dépend pas d’un ou plusieurs chercheurs et peut valoir pour une communauté large sur le long terme, et l’"interprétation" propre à une expérience, un projet de recherche, une école, ou une discipline. Cette information s’est jusqu’ici inscrite sous forme de balises, dans un schéma XML (ou SGML) ; mais elle est aussi réfléchie comme des "principes abstraits", indépendants de toutes technologies, afin de faciliter l’importation en provenance d’autres formats, ainsi que le transcodage dans les formats futurs.


La TEI a été initiée en 1987 par trois sociétés savantes, l, l'" et l''. 

À l'heure actuelle, le « TEI Consortium » est une institution sans but lucratif financée par ses 64 membres , parmi lesquels on compte : le "Research Technologies Service" à l'université d'Oxford (Royaume-Uni) ; le "Scholarly Technology Group" à l'université Brown (États-Unis) ; un groupe francophone de recherche, à Nancy, composé de l'ATILF, de l'INIST, et du LORIA ; l'"Electronic Text Center" et l"'Institute for Advanced Technology in the Humanities" à l'université de Virginie (États-Unis) ; OpenEdition (France).

Le consortium s’organise en différentes instances. La TEI "Board of Directors" (conseil d’administration) décide de la direction stratégique et de la gestion financière. La TEI "Technical Council" (conseil technique) maintient et développe les recommandations ainsi que les systèmes TEI. Les TEI "Workgroups" (groupes de travail) sont des groupes spécialisés conduits par le conseil technique qui doivent faire des propositions concrètes pour les recommandations (ex : bibliographie, encodage de caractères…). Finalement, les TEI "Special Interest Groups" (groupes d’intérêt spécifique) sont des groupes qui travaillent autour d’un sujet en lien avec la TEI mais pas nécessairement destiné à alimenter les recommandations (ex : outils, correspondances, enseignement…).

Pour illustrer la philosophie de la TEI, voici comment pourrait être codé un extrait du "Cid" de Pierre Corneille.

On cherche à représenter :
Avec le langage HTML, on aurait une codification limitée aux aspects « mise en page ».

Avec le schéma TEI, on obtiendrait ceci :
La TEI permet de décrire la structuration du texte tel qu'il a été conçu et non son rendu final (présentation). En fait, « les conventions élaborées dans le cadre du TEI visent à permettre la description de la manière dont un document a été créé ainsi que la façon dont il a été structuré : pages, paragraphes, lignes, chapitres, dialogues, soulignements, ajouts marginaux, ratures, etc. ». 

Cet exemple montre notamment l'imbrication des actes et des paragraphes (2 éléments codice_1 imbriqués) (avec un langage comme XPath, il est alors possible d'extraire un acte ou une scène), le découpage du dialogue par des éléments codice_2, la définition des interlocuteurs par des éléments codice_3 (il est possible facilement de lancer des requêtes pour localiser les endroits où Rodrigue cite Chimène) ainsi que la précision de la description de la versification par des éléments codice_4 (ligne) avec des indications sur la position d'un élément de dialogue en début, fin ou milieu de vers grâce aux attributs codice_5.

La TEI n’est pas le seul langage de balisage de document. Sa naissance doit beaucoup à la normalisation officielle de SGML ISO 8879:"1986" qui posait déjà les principes fondamentaux qui inspirent TEI. En effet, une application SGML doit distinguer strictement un schéma (DTD), une feuille de style isolant les informations de présentation, et des documents purement sémantiques, balisés selon ce schéma.

Vers la même époque sont apparues d’autres applications SGML dont certaines existent encore, DocBook (1991), EAD (1993), ou HTML (1993). Ces trois exemples permettront de mieux situer TEI par comparaison avec d’autres milieux et besoins s’emparant de la même norme SGML. Docbook, EAD, et HTML permettent de bien situer la différence de TEI parce que beaucoup de membres de la communauté connaissent très bien ces autres schémas, et se situent relativement à eux. S’intéressant d’abord à l’encodage des textes du patrimoine, ce schéma concerne surtout les milieux académiques, les institutions de conservation (bibliothèques, archives), et parfois un peu, les maisons d’édition.

Dès sa naissance, Docbook s’est concentré sur la documentation technique, et plus particulièrement, informatique. En associant le développement logiciel UNIX (commercial et libre) avec un éditeur de livres informatique O'Reilly, le schéma s’est donné d’emblée plusieurs destinations à satisfaire automatiquement à partir d’un même document balisé : impression papier, man page (manuel UNIX pour la console), puis HTML. La communauté est organisée comme un projet logiciel libre, avec un comité qui se réunit régulièrement pour présider à la croissance ordonnée du schéma selon les propositions des utilisateurs. 

Ce schéma est de taille comparable à TEI (v5, ~400 éléments), mais plus limité car plus précis dans ses objectifs. Docbook distingue par exemple explicitement les éléments codice_6 tandis que TEI a essentiellement un seul élément structurant à ce niveau codice_7, qui peut être précisé par un attribut @type. La TEI ne suggère pas une liste de valeurs pour qualifier les types de divisions, si bien qu’une application TEI ne sait pas a priori comment traiter les divisions, ne serait-ce que pour en extraire une table des matières qui s’arrête au niveau des chapitres. Il faut cependant comprendre que DocBook se destine principalement à la production de nouveau documents, que le schéma peut être normatif, et imposer une définition limitée des composants d’un livre. La TEI permet de produire des documents nouveaux, mais sa mission première est l’encodage pérenne des textes du patrimoine. Or, un manuscrit, une correspondance, une pièce de théâtre, beaucoup de types de documents ne se structurent pas selon les notions de chapitres et de sections. Si tous les composants textuels de la tradition avaient produit un élément comme dans Docbook, le schéma risquait une inflation incontrôlable, avec des casse-têtes indécidables (ex : si une lettre est un chapitre structurant dans une correspondance, peut-on choisir le même élément pour une lettre citée dans un roman structuré en chapitres ?). 

L’attention que la TEI porte au texte lui complique lourdement la tâche d’exploitation des documents. Le simple développement de feuilles de style ne donne pas des résultats satisfaisants pour toute la variété des documents possibles. Docbook, grâce à la restriction de ses objectifs, est un modèle de déploiement applicatif d’un schéma (ex : la plupart des distributions linux ont un paquet pour le schéma Docbook et les transformations XSLT). 

Comme la TEI, l’EAD ("Encoded Archival Description" : description archivistique encodée) concerne les documents patrimoniaux ; mais il s’agit d’un schéma métier, restreint dans son approche et sa vision du document. C’est d’abord la transposition XML de la Norme générale et internationale de description archivistique, l’ISAD(G). L’EAD encode principalement des inventaires de fonds d’archives, mais elle dispose d’assez d’éléments et d’attributs pour transcrire le texte des documents. 

EAD a beaucoup emprunté à la TEI codice_8, elle pourrait aussi lui apporter plus, par exemple par son appareil d’indexation des entités nommées (personnes, lieux, dates…). Si les deux schémas peuvent partager certains objets et éléments, les différences permettent de mieux qualifier la TEI. L’EAD ne comporte pas plus de 150 éléments, car elle doit être intégralement comprise par les archivistes qui l’emploient. Même si l’EAD a une origine universitaire (1993, Berkeley), elle a ensuite été reprise par la société des archivistes américains, soutenue par la Bibliothèque du Congrès.

Elle est très stable dans le temps : la version 1 date de 1998 (SGML), la version 2 date de 2002 et consiste surtout à transposer la version 1 en XML, une nouvelle version est annoncée pour 2016. L’EAD pourrait représenter une sorte d’idéal d’interopérabilité pour les documents XML patrimoniaux, mais ce résultat s’obtient par une grande limitation.

HTML s’affiche comme une application SGML, souhaitant respecter les principes de séparation entre sémantique et présentation, avec une centaine d’éléments. Cependant les éléments sémantiques codice_9 se mélange souvent avec l’apparence codice_10. Cette confusion était nécessaire parce qu’au commencement des navigateurs, il n’y avait pas de langage adapté à la définition de feuilles de style pour l’écran, ce que devinrent les CSS. Pour qu’un sous-ensemble de la TEI puisse être le format de l’Internet, il aurait fallu plus de liens avec l’industrie, que l’équilibre de son consensus puisse accepter des éléments comme codice_11, conformément à un des principes de Poughkeepsie « les recommandations doivent inclure un ensemble minimal de conventions pour l’encodage de nouveaux textes ». Notons que Docbook n’a pas non plus été repris par le W3C, mais que depuis 2014, HTML5 reprend quelques leçons sémantiques de ces schémas en introduisant les éléments codice_12.

Les 550 éléments de la TEI (en 2015) constituent un dictionnaire très important, avec une combinatoire potentiellement imprévisible. Cette complexité serait difficile à maîtriser dans sa totalité, tant par les utilisateurs que les développeurs, s’il n’y avait pas des regroupements et de la hiérarchie. 

Comme n’importe quel langage de programmation, les syntaxes de schéma permettent de factoriser des déclarations répétitives. Soit par exemple la structure de contenu d’un paragraphe, il peut enchâsser du texte et des balises diverses : italique, noms de personnes, apparat critique… Un item de liste, une note de bas de page, ou une citation, bien d’autres éléments textuels peuvent partager une structure de contenu similaire à un paragraphe. Il ne serait pas rationnel de répéter la même déclaration pour chaque conteneur de niveau paragraphe, d’autant que cela compliquerait la maintenance du schéma (si par exemple un élément est introduit, il faudrait l’ajouter dans tous les lieux où il peut être pertinent). Dès SGML, les DTDs proposèrent le mécanisme des entités paramètres, sur le modèle des macros. Un langage de schéma XML permet donc de définir des raccourcis pour remplacer une déclaration plus importante. 

Ainsi par exemple, la TEI a une "macro.paraContent" qui définit le contenu de 52 éléments différents. Modulariser un gros schéma n’est pas spécifique à TEI, EAD a une macro "para.content", HTML parle de "flow content", et Docbook stipule que les paragraphes, comme les citations ou les titres, contiennent tous les éléments de niveaux caractère ("inline"). Par ailleurs, comme une macro peut contenir une macro, récursivement, un schéma peut devenir une véritable ontologie de l’objet qu’elle modélise. Ce qui est original à TEI, c’est de montrer ces macros dans la documentation, parce qu’elles ne sont pas seulement des commodités de développeurs, mais une tentative scientifique pour décrire tous les textes possibles.

Cet idéal d’organisation est cependant pondéré par l’effet social des groupes de travail à l’origine de la documentation. Selon les principes de “Poughkeepsie”, le schéma TEI se veut aussi bien décrit pour les machines que pour les humains. L’édifice s’est donc constitué en croisant l’effet de deux logiques appliquées aux textes : l’intelligence, concevant le plan général, et l’informatique, validant les détails. Il en résulte une structuration de la documentation qui apparait dès 1992, dans la table des matières de la TEI P2. L’ordre et l’organisation de ces chapitres a varié en une vingtaine d’années, mais pas les titres, que l’on retrouve presque à l’identique en 2015. Chaque chapitre de prose documente un module du schéma presque indépendant, si bien que la TEI n’est pas un schéma, mais une bibliothèque de schémas librement combinables. Le consortium propose même un formulaire en ligne, "Roma", pour que chacun puisse se construire son propre profil TEI, adapté à son corpus.

Par exemple, le noyau de balises "Core Tags and General Rules" comprend le l’entête TEI ou la page de titre électronique ("TEI Header") et les balises communes à tous les schémas ("Tags Available in All TEI DTDs"). Les balises spécifiques de description des textes "Base Tag Sets" comprend le "Base Tag Set for Prose" (prose), le "Base Tag Set for Verse" (poésie), le "Base Tag Set for Drama" (théâtre), le "Base Tag Set for Transcriptions of Spoken Texts" (oral), le "Base Tag Set for Printed Dictionaries" (dictionnaires), etc. Enfin, les autres balises "Additional Tag Sets" comprennent des outils d'interprétation de liens, de segmentations et d'alignements ("Segmentation and Alignment"), des degrés de confiance du balisage interprétatif ("Certainty"), de manuscrits ("Manuscripts, Analytic Bibliography, and Physical Description of the Source Text"), des entités nommées ("Additional Tags for Names and Dates"), des graphes ("Graphs, Digraphs, and Trees"), des figures comme les tables, formules, images, partitions, etc. ("Graphics, Figures, and Illustrations" ; "Formulae and Tables") et des corpus linguistiques ("Additional Tag Set for Language Corpora"). Ces autres balises comprennent également des outils d'analyse linguistique des phrases, propositions, syntagmes, mots, etc. ("Simple Analytic Mechanisms"), des appareils pour d'autres analyses possibles comme la phonétique, la sémantique, les personnes, etc. ("Feature Structure Analysis"), ainsi que des apparats critiques ("Text Criticism and Apparatus").

Cette apparente liberté modulaire bute cependant sur la pertinence des divisions imposées. Depuis la TEI P4 (2001), la table des matières ne hiérarchise plus les chapitres, ce qui masque l’articulation de ces différents groupes de balises. On retrouve pourtant l’intention initiale de distinguer profondément ce qui relève de la description des textes, et de leur interprétation. Cette distinction reste hautement pertinente et toujours à rappeler, même s’il y a nécessairement de l’imprécision sur les franges.

Lorsque l’on entre dans le détail, les chapitres ne sont pas également heureux. Le chapitre sur les dictionnaires par exemple, signé par Nancy Ide et Jean Véronis, est d’une qualité de modélisation toujours actuelle. Par contre, la distinction traditionnelle entre vers et prose bute frontalement sur la réalité des textes. Le théâtre classique est notoirement en vers ou en prose. Le roman semble par exemple un genre typique de la prose, pourtant "Alice au pays des merveilles" ou "Le livre de le Jungle" contiennent des chansons et donc des vers. Un roman français, par exemple Balzac, citera des lettres ou des affiches publicitaires. La critique littéraire peut citer du théâtre ou de la poésie. Lorsqu’on en vient à chercher les éléments les plus pertinents pour décrire un texte, il est nécessaire de piocher des exemples et des idées dans tous les chapitres. Les divisions de l’ontologie TEI ne fonctionnent pas vraiment. Cet ordre a été utile à la production de la documentation et reste assez logique comme plan d’exposition, mais il est à la fois trop contraignant, et pas assez, dès que l’on se met en contact avec les textes.

Les appareillages proposés pour l’interprétation sont très inégaux. Le chapitre sur les graphes, par exemple, semble désormais obsolète depuis la généralisation de RDF-OWL, largement plus employé, avec un grand support logiciel. En 1990, on pouvait comprendre que la TEI doivent contenir tous les types d’outils de balisage. Depuis la spécification sur les espaces de noms XML (1999), il semble beaucoup plus pertinent d’insérer un langage spécialisé comme OWL dans du TEI. 

L’universalité actuelle de HTML pourrait même suggérer d’en faire le noyau de la TEI, afin qu’elle se concentre sur son apport académique, plutôt que de répéter par exemple, un même appareillage pour les tables, qui ne diffère de HTML que par les noms.

Cette science académique du texte informatisé mérite pourtant de devenir le standard de la révolution du livre électronique en cours dans l’édition, afin d’envisager l’encodage des textes à la source, dès la production.

En 2015, une standardisation de la TEI se met en place dans l’édition académique, notamment avec le dynamisme des Presses universitaires de Caen auprès des autres presses universitaires ainsi que l’infrastructure OpenEdition, qui promeuvent ensemble leur profil TEI. Ce mouvement intéresse aussi des maisons d’édition privées, par exemple la Librairie Droz, confrontée comme bien d’autres à la diffusion multi-support, tant papier, que livre électronique, ou bien de bases de textes en ligne.

Le vocabulaire TEI se diffuse, et avec lui un désir de pérennité, pour que les textes qui s’encodent actuellement soient compris par les générations suivantes.





