Hypercube (graphe)

Les hypercubes, ou n-cubes, forment une famille de graphes. Dans un hypercube formula_1, chaque sommet porte une étiquette de longueur formula_2 sur un alphabet formula_3, et deux sommets sont adjacents si leurs étiquettes ne diffèrent que d'un symbole. C'est le graphe squelette de l'hypercube, un polytope "n"-dimensionnel, généralisant la notion de carré ("n = 2") et de cube ("n = 3"). Dans les années 1980, des ordinateurs furent réalisés avec plusieurs processeurs connectés selon un hypercube : chaque processeur traite une partie des données et ainsi les données sont traitées par plusieurs processeurs à la fois, ce qui constitue un calcul parallèle. L'hypercube est couramment introduit pour illustrer des algorithmes parallèles, et de nombreuses variantes ont été proposées, soit pour des cas pratiques liés à la construction de machines parallèles, soit comme objets théoriques.

L'hypercube formula_4 consiste en deux sommets d'étiquettes formula_5 et formula_6 ; les étiquettes de ces sommets étant différentes par un seul symbole, ils sont donc reliés. Pour passer à la dimension supérieure, on fabrique une copie du graphe : à la partie d'origine, on rajoute le symbole formula_6, et sur la partie copiée le symbole formula_5 ; chaque sommet de la partie d'origine est ensuite relié à son équivalent dans la copie. Ainsi, formula_9 consiste en quatre sommets étiquetés formula_10, formula_11, formula_12 et formula_13. L'illustration ci-dessous montre en rouge les arêtes connectant les sommets d'origine à leurs équivalents dans la copie, et l'exemple se poursuit jusqu'à formula_14 et formula_15. Cette méthode de construction est récursive, puisque pour construire formula_1 on se fonde sur formula_17.

On peut aussi définir formula_1 comme le produit cartésien de formula_2 graphes complets formula_20, soit : formula_21

Enfin, on peut construire le graphe directement en appliquant sa définition. On dispose formula_22 sommets, et chacun a une étiquette unique dans l'espace vectoriel formula_23, c'est-à-dire une étiquette de la forme formula_24. Deux sommets sont reliés par une arête s'ils diffèrent exactement sur un symbole de leurs étiquettes, soit formellement pour le graphe formula_25 : formula_26

Le graphe hypercube formula_14 est le graphe hexaédrique et formula_15 est le graphe tesseract.




Le groupe d'automorphisme formula_96 de l'hypercube formula_79 est d'ordre formula_98. Il est isomorphe au produit en couronne des groupes symétriques formula_99 et formula_100 : formula_101. Le "produit en couronne" de "A" par "B" étant défini comme le produit semi-direct formula_102 où formula_103 est l'ensemble des fonctions "de B dans A" et où "B" agit sur formula_104 par décalage d'indice :
formula_105 pour formula_106 et formula_107.

L'hypercube formula_79 est un graphe arc-transitif : son groupe d'automorphisme formula_96 agit transitivement sur l'ensemble de ses arcs. Étant donné deux arêtes "e" = "u""v" et "e" = "u""v" de "G", il existe deux automorphismes formula_110 et formula_111 tels que formula_112, formula_113, et formula_114, formula_115, formula_116, formula_117.

L'hypercube formula_79 est donc "a fortiori" symétrique. Le groupe formula_96 agit donc également transitivement sur l'ensemble de ses sommets et sur l'ensemble de ses arêtes. En d'autres termes, tous les sommets et toutes les arêtes d'un hypercube jouent exactement le même rôle d'un point de vue d'isomorphisme de graphe.

Le graphe hexaédrique (formula_14) est l'unique graphe cubique symétrique à 8 sommets. Le graphe tesseract (formula_15) est l'unique graphe symétrique régulier de degrés 4 à 16 sommets.

L'hypercube formula_79 est un graphe de Cayley "Cay(G, S)" avec :
formula_123
formula_124
Cela découle d'une propriété plus générale statuant que tous les graphes de Hamming sont des graphes de Cayley.

La matrice d'adjacence formula_125 de l'hypercube formula_4 est définie ci-dessous. Par la définition récursive de l'hypercube, pour passer à la dimension supérieure formula_9, on duplique formula_4 et connecte les sommets d'origine à leur équivalent dans la copie.
On obtient ainsi la matrice d'adjacence formula_129 ci-dessous :
Au niveau de la matrice, l'opération passant de formula_4 à formula_9 se comprend comme suit : les entrées formula_132 correspondent à la matrice d'origine, et se trouvent dupliquées en formula_133. Dans les autres entrées, on connecte chaque sommet à sa copie. Ainsi, la forme générale de la matrice est donnée de la façon suivante, où formula_134 représente la matrice identité de dimension formula_135 : formula_136

Pour comprendre l'évolution du spectre de la matrice en fonction de formula_2, il faut revenir à la définition comme produit cartésien. Le spectre d'un produit cartésien formula_138 est formula_139, où formula_140 est le spectre de formula_141 et formula_142 le spectre de formula_143 ; autrement dit, le spectre est la somme de toutes les paires possibles. Sachant que le spectre de formula_144 est formula_145, on en déduit que le spectre de formula_9 est formula_147 : en effet, elles correspondent aux combinaisons formula_148, formula_149, formula_150. Si l'on passe au stade suivant, soit formula_14, on a d'un côté le spectre formula_147 de formula_9, et de l'autre formula_154 de formula_20 : le résultat du produit cartésien est formula_156.

On en déduit par récurrence la formule suivante pour le polynôme caractéristique de la matrice d'adjacence (et donc du graphe):

Pour aller d'un sommet à un autre, on utilise à nouveau le fait que deux sommets sont connectés s'ils diffèrent exactement sur un symbole de leurs étiquettes. Ainsi, un chemin est trouvé en faisant correspondre une à une les coordonnées du sommet de destination avec celui d'origine. Par exemple, pour aller de formula_158 à formula_159, on obtient formula_160. Dans le cas général, pour aller de formula_161 à formula_162 on obtient :formula_163
Notons deux choses. Premièrement, la longueur d'un chemin entre deux sommets est le nombre de symboles sur lesquels leurs étiquettes diffèrent : ainsi, si les étiquettes sont complètement différentes, le chemin sera de longueur formula_2, ce qui est une autre explication quant au diamètre du graphe. Deuxièmement, le chemin choisi n'est pas unique : au lieu d'aller de formula_158 en formula_166, on aurait tout d'abord pu passer par formula_167 avant d'aller en formula_159. Le nombre de chemins différents pour aller entre deux sommets est un problème de combinatoire : considérons que les sommets diffèrent sur formula_73 symboles, combien de façons a-t-on de générer des chemins ? On a formula_73 choix pour le premier symbole à changer, puis formula_171 choix pour le second symbole à changer, jusqu'à un seul choix quand il n'y a plus qu'un symbole à changer ; ainsi, le nombre de chemins entre deux sommets différant sur formula_73 symboles est formula_173.

Les chemins entre deux sommets ont d'autres propriétés intéressantes, particulièrement pour les sous-graphes qu'ils définissent. Ainsi, l'union des chemins entre deux sommets distants de formula_73 ("i.e." différant de formula_73 symboles) donne l'hypercube formula_176. Ceci est illustré par l'exemple ci-dessous : dans le cas de deux sommets voisins formula_177 et formula_178, il n'y a qu'un chemin et on obtient l'hypercube formula_4 ; dans le cas où ils sont à distance 2, il y a deux chemins entre eux qui définissent formula_9, et s'ils sont à distance 3 alors l'union des chemins représente l'ensemble de l'hypercube formula_14.
Le nombre formula_182 d'hypercubes formula_79 compris dans formula_1 est donné par la formule suivante : formula_185
L'hypercube est aussi un graphe médian, et en particulier le seul graphe médian régulier. On peut donc appliquer la formule suivante des graphes médians :
formula_186

Certains types de sous-graphe sont particulièrement utiles en termes de communications. Par exemple, un "spanner" est un sous-graphe couvrant, c'est-à-dire qui contient tous les sommets, mais qui contient moins d'arêtes. Contenir moins d'arêtes peut augmenter les distances entre des sommets du graphe, et l'on distingue ainsi les spanners multiplicatifs, où la distance peut être multipliée par un facteur formula_73, des spanners additifs où la distance peut être augmentée d'un montant formula_73. Dans le cas d'un spanneur additif sur formula_1, des résultats concernent les degrés du spanneur :
De nombreuses études sur les spanners, et des constructions pour des modèles généralisés de l'hypercube, sont dues à Arthur L. Liestman et Thomas C. Shermer. Ils ont en particulier proposé un spanner additif avec un montant formula_197 où les arêtes sont celles dont les extrémités formula_198 sont données par les trois conditions suivantes :
Ce processus est illustré dans l'image ci-contre où les arêtes satisfaisant une des conditions sont surlignées ; l'ensemble de ces arêtes constitue le spanner. Pour obtenir un chemin entre deux sommets, considérons que l'on démarre d'un sommet formula_202. On inverse d'abord ses coordonnées paires, car la condition (1) impose l'existence d'une arête sur tout sommet commençant par 0 avec une différence sur bit pair. On change ensuite la première coordonnée en 1 grâce à la condition (3), à partir de quoi on peut inverser toutes les coordonnées impaires par la condition (2). Si le sommet de destination est formula_203 alors on est arrivé car on commence par 1 et les coordonnées paires comme impaires ont pu être inversé ; si le sommet de destination est formula_204 on utilise une dernière inversion par la condition (3). Le cas où le sommet d'origine est formula_205 est traité de façon similaire : inverser les coordonnées impaires, passer la première coordonnée en 0, inverser les coordonnées paires, passer la première coordonnée en 1 si nécessaire. Dans l'image ci-contre, on voit le délai de 2 si on cherche un chemin de formula_206 à formula_207 : ce qui se ferait normalement directement en une étape doit se faire en trois étapes, en passant par formula_208 et formula_209.

Dans le problème de la diffusion (anglais "broadcast"), un nœud source souhaite diffuser une information à tous les autres nœuds. Dans le modèle classique, à chaque étape un nœud donné peut transmettre au plus une information, cette information utilisant une arête et étant transmise à la fin de l'étape. Dans ce modèle, la diffusion la plus performante est celle où, à chaque étape, chaque nœud en contacte un autre, c'est-à-dire que le nombre de nœuds contactés est doublé. Le nombre d'étapes minimal est donc formula_210 ; un graphe pouvant finir une diffusion en formula_210 étapes quelle que soit l'origine et en minimisant le nombre d'arêtes est un "graphe de diffusion minimale" (anglais "minimal broadcast graph"). Dans le cas où formula_212, le nœud source doit avoir au moins formula_73 voisins car il doit diffuser à chaque étape pour faire doubler le nombre de voisins ; la source n'étant pas fixée, on obtient que chaque nœud doit avoir au moins formula_73 voisins d'où formula_215 arêtes (formula_216 vient du partage de chaque arête dans un graphe non-orienté), ce qui est précisément le cas d'un hypercube. Ainsi, l'hypercube est un graphe de diffusion minimale.

Parmi les problèmes proches se trouve le commérage (anglais "gossip") où chaque nœud veut échanger une information avec tous les autres, autrement dit chaque nœud est la source d'une diffusion. Des cas particuliers s'intéressent aux variantes locales : par exemple, dans un commérage 'local', chaque nœud veut apprendre les messages de ses voisins.

Pour avoir une idée du gain en performances en utilisant des machines parallèles, considérons l'addition de formula_217 nombres. Sur une machine séquentielle, on additionne le premier nombre avec le second, puis on rajoute le troisième, etc., Au total, formula_218 étapes sont nécessaires. Sur une machine parallèle, chaque processeur réalise l'addition d'une paire de nombres en une étape, puis les résultats de deux paires sont additionnés, etc. Au total, formula_219 étapes sont nécessaires. Ainsi, pour nombres, une machine séquentielle utilisera 999 étapes tandis qu'il n'en faut que 11 sur une machine parallèle ; un autre exemple est illustré ci-contre. Le gain est encore plus significatif pour d'autres opérations, par exemple une instance d'inversion de matrice peut nécessiter étapes sur une machine séquentielle contre 61 sur une machine parallèle.

Au début des années 1960, des idées furent proposées pour concevoir un ordinateur parallèle avec une architecture en hypercube : « il y a formula_22 modules, chacun connecté directement à formula_2 autres ; en particulier, chaque module est placé sur le sommet d'un cube n-dimension, et les arêtes de ce cubes sont les câbles ». Les justifications dans le choix de l'hypercube peuvent paraître faibles au regard des connaissances actuelles sur les familles de graphes, mais il s'avère que l'hypercube a de nombreuses propriétés utiles : il est arc-transitif et distance-transitif, ce qui implique que toutes ses arêtes jouent le même rôle et que tous ses sommets ont les mêmes propriétés de distance. Par ailleurs, le compromis entre le degré des sommets et la distance entre eux reste raisonnable, et la navigation peut se faire de façon délocalisée, ce qui est une des principales raisons citées à l'origine. En résumé, les propriétés de transitivité permettent d'obtenir une égalité entre les processeurs, et la communication entre les processeurs peut être rapide (distance faible) en ayant besoin de peu d'informations (délocalisé).

Vingt ans se sont écoulés entre les idées du début des années 1960 et la première production, avec le "Cosmic Cube" de Caltech (64 processeurs Intel 8086/86 embarquant chacun 128Kb de mémoire) en 1983. De nombreuses autres machines sont alors produites, comme les Ametek série 2010, les CM-1/CM-2, les et les iPSC d'Intel. De nombreuses études sur les performances des machines parallèles utilisant une architecture en hypercube sont réalisées au laboratoire national d'Oak Ridge sous le contrat DE-AC05-84OR21400. En effet, ce laboratoire créé à l'origine pour le Projet Manhattan (conception de la première bombe atomique) s'est reconverti sur des sujets tels que la sécurité nationale et les supercalculateurs. Parmi les modèles étudiés figurent les Intel iPSC/860, iPSC/1 et iPSC/2, ainsi que les nCUBE 3200 et 6400 ; les caractéristiques de ces machines sont résumées ci-dessous.

Les performances précises de ces processeurs peuvent être trouvées dans les rapports d'Oak Ridge. Au niveau de l'analyse des performances pour la communication, il est préférable d'utiliser un modèle à coût linéaire plutôt qu'à coût constant. Autrement dit, on ne peut pas considérer qu'envoyer un message formula_222 ait un coût en temps fixe formula_223 quelle que soit la longueur du message : on considère plutôt que le coût en temps est fonction de la longueur du message, et qu'initier la transmission a également un coût formula_224, ce qui entraîne le modèle formula_225. Le coût formula_224 est significatif par rapport à formula_227 : cela prend par exemple prend 697µs pour établir la communication dans un iPSC/2, mais seulement 0.4µs pour chaque bit transmit.

De nombreuses informations sur les algorithmes pour des architectures en hypercubes à la fin des années 80 furent publiées dans la troisième conférence "Hypercube Concurrent Computers and Applications" (« Ordinateurs concurrents en hypercube et applications »). Utiliser une machine parallèle n'augmente pas "automatiquement" la performance d'un algorithme : non seulement les algorithmes doivent être conçus de façon à tirer profit de l'architecture, mais les données ne peuvent pas toujours être partitionnées pour être traitées par différents processeurs, et ces processeurs ont également besoin de communiquer. Dans l'exemple de l'addition, le coût de communication était considéré comme négligeable, et ceci est l'hypothèse que nous conserverons par la suite : en effet, les propriétés de la machine (temps de communication, lecture/écriture, ...) sont généralement ignorés dans l'analyse des algorithmes, et on se concentre sur les dépendances entre les données et les façons de rendre le calcul parallèle sur un hypercube.

Une des opérations les plus courantes en traitement d'image consiste à utiliser un filtre linéaire, c'est-à-dire à appliquer une matrice de convolution. Pour bénéficier de l'architecture en hypercube, l'image doit être divisée en zones égales, et chaque zone assignée à un processeur. Mudge et Abdel-Rahman ont suggéré de considérer l'image comme étant une table de Karnaugh utilisant le code de Gray, ainsi que sur l'exemple ci-contre : si on considère une zone de l'image et ses coordonnées dans la table, alors on obtient directement le processeur auquel l'assigner. Par ailleurs, l'utilisation du code de Gray conserve l'adjacence : deux zones adjacentes dans l'image seront placées sur deux processeurs adjacents, sauf pour les coins. Le filtre, tel que celui de Sobel, est appliqué par chaque processeur à la zone qui lui est assignée. Si le filtre a besoin de certains pixels dépassant la zone disponible à un processeur, il peut la demander au processeur voisin en utilisant les propriétés d'adjacence ; pour des coûts plus faibles en communication, chaque processeur peut également avoir une zone de l'image dont la taille correspond à celle nécessaire pour le traitement plutôt qu'à une partition stricte.

Un plongement permet à ce qu'un réseau soit simulé par un autre : aux sommets du réseau d'origine sont associés des sommets dans le réseau simulant, et deux sommets voisins sont séparés par un chemin. Ainsi, un algorithme conçu spécialement pour un réseau peut être réutilisé dans un autre grâce à un plongement. On s'intéresse donc à deux cas : réutiliser des algorithmes sur des hypercubes (1), ou utiliser des algorithmes pour l'hypercube dans d'autres réseaux (2). Autrement dit, l'hypercube est soit un réseau simulant (1), soit un réseau simulé (2). La qualité d'un plongement permet de savoir quelles sont les différentes pertes en performance de l'algorithme. Pour cela, on considère plusieurs facteurs :

Pour l'hypercube comme réseau simulant, toute grille à deux dimensions a un plongement avec une dilatation d'au plus 2 et une expansion minimale, une grille à trois dimensions a une dilatation entre 2 et 5, et l'arbre binaire complet à formula_135 nœuds a un plongement de dilatation 1 sur formula_229.

Si un programme utilise plusieurs tâches et que l'on a des informations sur la façon dont ces tâches communiquent, alors il peut être possible de faire bénéficier le programme d'une machine parallèle. En effet, la structure de la communication des tâches définit un graphe, et celui-ci peut être simulé entre autres par un hypercube en cherchant un plongement, tel qu'étudié dans la section précédente. Dans l'autre cas extrême, si toute tâche communique fréquemment avec toutes les autres, alors les communications sont données par un graphe complet et la simulation par une machine parallèle est peu performante. Des solutions intermédiaires ont été développées s'il n'y a pas d'informations sur la communication des tâches mais qu'elle se fait à fréquence modérée.

L'hypercube était très utilisé pour les architectures de machines parallèles, et certaines de ses propriétés étaient jugées perfectibles dans ce cadre. Le principal problème est la croissance d'un hypercube, où le nombre de sommets doit doubler d'une dimension à l'autre : dans une machine, plus de flexibilité est désirable afin de pouvoir ajouter "quelques" processeurs. Plusieurs aspects sont aussi liés à sa réalisation par des circuits électroniques. Premièrement, l'hypercube n'est pas planaire et aura donc des chevauchements dans le circuit : en réduire le nombre simplifie le circuit. Deuxièmement, l'hypercube est défini comme un graphe non-orienté, mais « un réseau basé sur une orientation formula_230 de formula_231 utilise la moitié du nombre de broches et câbles par rapport à formula_231 » : il est donc intéressant de trouver une orientation conservant des performances similaires. Enfin, il peut être désirable de réduire les distances dans l'hypercube pour les performances en termes de communications.

Un "hierarchical cubic network" formula_233 est formé de formula_22 formula_2-cubes, où chaque cube est désigné comme un "cluster". Chacun de ces clusters est utilisé comme un bloc de base, et chaque nœud d'un cluster a un lien supplémentaire le reliant à un autre cluster ; ces liens sont déterminés par l'algorithme suivante pour le graphe formula_25 composé de formula_22 formula_2-cubes, où formula_239 désigne le sommet formula_240 du cluster formula_241 et formula_242 est le complément bit à bit de formula_243 :

formula_244

Les auteurs montrèrent que, à tailles égales, ce graphe a un diamètre d'un quart plus faible que celui de l'hypercube, et la moitié du nombre de liens. Cependant, dans certaines situations la diffusion est plus lente que sur un hypercube, et avoir un graphe moins dense revient à être plus exposé lorsque des pannes surviennent sur les liens.

Une autre variante ayant été depuis particulièrement étudiée est le "Cube de Fibonacci". Les conditions fondamentales du cube de Fibonacci de dimension formula_2, noté formula_246, sont les mêmes que celles de l'hypercube : chaque sommet porte une étiquette de longueur formula_2 sur un alphabet formula_3, et deux sommets sont adjacents si leurs étiquettes ne différent que d'un symbole. Cependant, on rajoute une contrainte : une étiquette valide ne peut avoir deux formula_6 consécutif. Ainsi, ci-dessous, on voit que les cubes de Fibonacci formula_250 peuvent se retrouver comme sous-graphes des hypercubes formula_251 en éliminant les étiquettes contenant deux formula_6 consécutifs.

La construction par récurrence peut être définie par une grammaire formelle en énonçant les étiquettes valides pour les sommets, puis en considérant le graphe formula_246 comme le sous-graphe de l'hypercube formula_1 induit par les sommets valides formula_255 :
formula_256

Dans le cas où réduire la distance soit le principal objectif, il est courant d'utiliser des procédures de recâblage comme on le voit encore dans le cas de l'effet petit monde. De nombreuses procédures ont été proposées, et les plus significatives sont résumées dans le tableau ci-dessous avec leurs performances sur la distance maximale ("i.e." le diamètre) et moyenne ainsi que le nombre de recâblages nécessaire. Le nom de chacune des procédures est conservé à partir des articles d'origines, où "twisted" signifie recâblé, et suivi de l'année à laquelle la procédure fut publiée.

Dans les années 2000, de nombreux modèles furent proposés pour prendre en compte des caractéristiques communes à de nombreux réseaux. Deux des principales caractéristiques sont l'effet "petit monde" et l'effet "libre d'échelle". Il est possible de modifier un hypercube afin d'obtenir l'effet libre d'échelle, tout en continuant à bénéficier de sa propriété de routage local. Pour cela, des sommets sont contractés à la condition qu'ils ne diffèrent que sur une coordonnée qui sera remplacé par un joker « _ ». Après une séquence de contractions, c'est-à-dire plusieurs contractions successives, il est toujours possible de trouver un chemin d'un sommet formula_141 à un sommet formula_143 en utilisant leurs coordonnés et en remplaçant les jokers « _ » par les coordonnées de formula_143.

La condition de ne différer que sur une coordonnée tout en opérant une séquence de contractions conduit à ce qu'un sous-hypercube soit contracté, et le degré du sommet formula_260 résultant de la contraction d'un hypercube formula_261 dans formula_1, formula_263 est :
formula_264

En résumé, l'effet libre d'échelle est obtenu par contraction de sous-hypercubes de grande taille et les algorithmes de navigation n'ont pas besoin d'être modifiés.




