I. The Term Extraction Program

The term extraction program uses python. It requires nltk to run.

To install nltk -

http://nltk.org/install.html

You could then run the program using

python main.py foreground_filelist background_filelist [-m measure] [-d working_directory]

File lists are CONLL format files produced either by the NYU chunker we delivered last year, or the OpenNLP chunker that I thought BAE used last year.

You can find sample sets at: sample_foreground/ and sample_background/

-m could take 4 possible options: 'TFIDF', 'DRDC', 'KLDiv', 'Weighted'

KLDiv is KL divergence and Weighted is a combination of the other three measures.

Weighted will be used by default.

-d could be used to provide the working directory where temporary files will be stored.

. will be used by default.

II. The Term Extraction Program with Filtering

We incorporated Adam's term filtering program. For patents in computer science
and biomedical domains, we prepared a shortcut script. (DO NOT USE THE SHORTCUT
SCRIPT FOR OTHER DOMAINS. You will need to regenerate the dictonaries, see Section
III)

Using the provided files, you can run:

extract_and_filter.sh FOREGROUND_FILELIST BACKGROUND_FILELIST WORKING_DIR

which can be:

extract_and_filter.sh sample_foreground.pos.filelist sample_background.pos.filelist working

Results will be written to 3 files in WORKING_DIR: output.txt is all terms,
output.accept is the terms accepted by the filtering program, and output.reject
is the terms that are rejected.

You can edit extract_and_filter.sh to change the location of the term extraction
system, the cutoff (the larger the cutoff, the more terms will be kept), and
the dictionaries you plan to use.

III. GENERATING NEW FILTERING DICTIONARIES FOR OTHER DOMAINS

In short, dictionaries can be generated by running get_abbreviation_dict_patent.py
on a list of txt;fact files:

get_abbreviation_dict_patent.py txt_fact.list FULL_ABBREV_DICT ABBREV_FULL_DICT

where FULL_ABBREV_DICT ABBREV_FULL_DICT are output files used by extract_and_filter.sh

For detailed information, please refer to Section II in the attached 
README-FILTER-TERMS.txt file
