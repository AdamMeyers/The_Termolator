<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright ©2011 LexisNexis Univentio, The Netherlands. -->
<lexisnexis-patent-document schema-version="1.08" date-produced="20111004" file="CN1914667A.xml" produced-by="LexisNexis-Univentio" lang="eng" date-changed="20110504" time-changed="230110">
  <bibliographic-data lang="chi">
    <publication-reference publ-type="Application" publ-desc="Unexamined application for a patent for invention">
      <document-id>
        <country>CN</country>
        <doc-number>1914667</doc-number>
        <kind>A</kind>
        <date>20070214</date>
      </document-id>
    </publication-reference>
    <application-reference>
      <document-id>
        <country>CN</country>
        <doc-number>200580003955</doc-number>
        <date>20050531</date>
      </document-id>
    </application-reference>
    <language-of-filing>eng</language-of-filing>
    <language-of-publication>chi</language-of-publication>
    <priority-claims date-changed="20090305">
      <priority-claim sequence="1" kind="national">
        <country>JP</country>
        <doc-number>2004163071</doc-number>
        <kind>A</kind>
        <date>20040601</date>
      </priority-claim>
      <priority-claim sequence="1" data-format="original">
        <doc-number>163071/2004</doc-number>
      </priority-claim>
      <priority-claim sequence="1" data-format="epodoc">
        <doc-number>JP20040163071</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability date-changed="20091225">
      <gazette-reference>
        <date>20070214</date>
      </gazette-reference>
      <unexamined-printed-without-grant>
        <date>20070214</date>
      </unexamined-printed-without-grant>
    </dates-of-public-availability>
    <kind-of-official-gazette lang="eng">23-07</kind-of-official-gazette>
    <classification-ipc date-changed="20091227">
      <main-classification>
        <text>  G 10L  17/00   A</text>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>17</main-group>
        <subgroup>00</subgroup>
        <qualifying-character>A</qualifying-character>
      </main-classification>
      <further-classification sequence="1">
        <text>  G 10L  15/02   B</text>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>15</main-group>
        <subgroup>02</subgroup>
        <qualifying-character>B</qualifying-character>
      </further-classification>
      <further-classification sequence="2">
        <text>  G 10L  15/10   B</text>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>15</main-group>
        <subgroup>10</subgroup>
        <qualifying-character>B</qualifying-character>
      </further-classification>
      <further-classification sequence="3">
        <text>  G 10L  15/12   B</text>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>15</main-group>
        <subgroup>12</subgroup>
        <qualifying-character>B</qualifying-character>
      </further-classification>
    </classification-ipc>
    <classifications-ipcr date-changed="20091227">
      <classification-ipcr sequence="1">
        <text>G10L  17/00        20060101CFI20070214BHCN        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>C</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>17</main-group>
        <subgroup>00</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20070214</date>
        </action-date>
        <generating-office>
          <country>CN</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G10L  17/00        20060101AFI20070214BHCN        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>17</main-group>
        <subgroup>00</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20070214</date>
        </action-date>
        <generating-office>
          <country>CN</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G10L  15/00        20060101CLI20070214BHCN        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>C</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>15</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20070214</date>
        </action-date>
        <generating-office>
          <country>CN</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>G10L  15/02        20060101ALI20070214BHCN        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>15</main-group>
        <subgroup>02</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20070214</date>
        </action-date>
        <generating-office>
          <country>CN</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="5">
        <text>G10L  15/08        20060101A I20080531RMEP        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>15</main-group>
        <subgroup>08</subgroup>
        <classification-value>I</classification-value>
        <action-date>
          <date>20080531</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="6">
        <text>G10L  15/10        20060101ALI20070214BHCN        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>15</main-group>
        <subgroup>10</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20070214</date>
        </action-date>
        <generating-office>
          <country>CN</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="7">
        <text>G10L  15/12        20060101ALI20070214BHCN        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>15</main-group>
        <subgroup>12</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20070214</date>
        </action-date>
        <generating-office>
          <country>CN</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
    </classifications-ipcr>
    <classifications-ecla date-changed="20091227">
      <classification-ecla sequence="1" classification-scheme="EC" country="EP">
        <text>G10L 15/08</text>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>15</main-group>
        <subgroup>08</subgroup>
      </classification-ecla>
      <classification-ecla sequence="1" classification-scheme="ICO" country="EP">
        <text>S10L 15:10</text>
        <section>S</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>15</main-group>
        <subgroup>10</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <number-of-claims calculated="yes">9</number-of-claims>
    <invention-title id="title_chi" date-changed="20091229" lang="chi" format="original">说话人识别装置、程序及说话人识别方法</invention-title>
    <invention-title id="title_eng" date-changed="20091229" lang="eng" format="original">Speaker recognizing device, program, and speaker recognizing method</invention-title>
    <parties date-changed="20091225">
      <applicants>
        <applicant sequence="1" app-type="applicant">
          <addressbook lang="chi">
            <orgname>TOSHIBA TEC KK</orgname>
            <address>
              <country>JP</country>
            </address>
          </addressbook>
        </applicant>
      </applicants>
      <inventors>
        <inventor sequence="1">
          <addressbook lang="chi">
            <name>柿野友成</name>
          </addressbook>
          <addressbook lang="eng">
            <name>KAKINO TOMONARI,IKUMI TOMONORI</name>
            <address>
              <country>JP</country>
            </address>
          </addressbook>
        </inventor>
        <inventor sequence="2">
          <addressbook lang="chi">
            <name>伊久美智则</name>
          </addressbook>
        </inventor>
        <inventor sequence="1" data-format="original">
          <addressbook lang="chi">
            <name>柿野友成</name>
          </addressbook>
        </inventor>
        <inventor sequence="1" data-format="docdb">
          <addressbook lang="eng">
            <name>TOMONORI KAKINO TOMONARI IKUMI</name>
            <address>
              <country>JP</country>
            </address>
          </addressbook>
        </inventor>
        <inventor sequence="1" data-format="docdba">
          <addressbook lang="eng">
            <name>KAKINO TOMONARI,IKUMI TOMONORI</name>
            <address>
              <country>JP</country>
            </address>
          </addressbook>
        </inventor>
        <inventor sequence="2" data-format="original">
          <addressbook lang="chi">
            <name>伊久美智则</name>
          </addressbook>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="attorney">
          <addressbook lang="chi">
            <name>北京市柳沈律师事务所 (邵亚丽)</name>
          </addressbook>
        </agent>
        <agent sequence="2" rep-type="attorney">
          <addressbook lang="chi">
            <name>北京市柳沈律师事务所 (李晓舒)</name>
          </addressbook>
        </agent>
        <agent sequence="1" rep-type="attorney" data-format="original">
          <addressbook lang="chi">
            <name>北京市柳沈律师事务所 (邵亚丽)</name>
          </addressbook>
        </agent>
        <agent sequence="2" rep-type="attorney" data-format="original">
          <addressbook lang="chi">
            <name>北京市柳沈律师事务所 (李晓舒)</name>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <pct-or-regional-filing-data>
      <document-id>
        <country>WO</country>
        <doc-number>JP05009963</doc-number>
        <date>20050531</date>
      </document-id>
    </pct-or-regional-filing-data>
    <pct-or-regional-publishing-data>
      <document-id>
        <country>WO</country>
        <doc-number>2005/119654</doc-number>
        <date>20051215</date>
      </document-id>
    </pct-or-regional-publishing-data>
    <patent-family date-changed="20100529">
      <main-family family-id="3956464">
        <family-member>
          <document-id>
            <country>CN</country>
            <doc-number>1914667</doc-number>
            <kind>A</kind>
            <date>20070214</date>
          </document-id>
          <application-date>
            <date>20050531</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>WO</country>
            <doc-number>2005119654</doc-number>
            <kind>A1</kind>
            <date>20051215</date>
          </document-id>
          <application-date>
            <date>20050531</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>JP</country>
            <doc-number>2005345598</doc-number>
            <kind>A</kind>
            <date>20051215</date>
          </document-id>
          <application-date>
            <date>20040601</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>JP</country>
            <doc-number>3927559</doc-number>
            <kind>B2</kind>
            <date>20070613</date>
          </document-id>
          <application-date>
            <date>20040601</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>CN</country>
            <doc-number>100593194</doc-number>
            <kind>C</kind>
            <date>20100303</date>
          </document-id>
          <application-date>
            <date>20050531</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>JP</country>
            <doc-number>3927559</doc-number>
            <kind>B9</kind>
            <date>20070309</date>
          </document-id>
          <application-date>
            <date>20040601</date>
          </application-date>
        </family-member>
      </main-family>
      <complete-family family-id="3631817">
        <family-member>
          <document-id>
            <country>JP</country>
            <doc-number>3927559</doc-number>
            <kind>B9</kind>
            <date>20070309</date>
          </document-id>
          <application-date>
            <date>20040601</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>JP</country>
            <doc-number>3927559</doc-number>
            <kind>B2</kind>
            <date>20070613</date>
          </document-id>
          <application-date>
            <date>20040601</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>WO</country>
            <doc-number>2005119654</doc-number>
            <kind>A1</kind>
            <date>20051215</date>
          </document-id>
          <application-date>
            <date>20050531</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>JP</country>
            <doc-number>2005345598</doc-number>
            <kind>A</kind>
            <date>20051215</date>
          </document-id>
          <application-date>
            <date>20040601</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>CN</country>
            <doc-number>1914667</doc-number>
            <kind>A</kind>
            <date>20070214</date>
          </document-id>
          <application-date>
            <date>20050531</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>CN</country>
            <doc-number>100593194</doc-number>
            <kind>C</kind>
            <date>20100303</date>
          </document-id>
          <application-date>
            <date>20050531</date>
          </application-date>
        </family-member>
      </complete-family>
    </patent-family>
  </bibliographic-data>
  <abstract id="abstr_chi" date-changed="20091227" lang="chi" format="original">
    <p num="1">为了能够实现精度高的说话人识别，使用两个特征参数时间序列A、B的各自的Δ间距时间序列，通过DP匹配单元(11)求音韵性距离的总和最小的最佳匹配序列F，使用该最佳匹配序列和两个特征参数时间序列A、B的各自的倒谱系数时间序列，通过说话人之间距离计算单元求个人性距离的总和，基于该总和，通过辨认单元进行说话人的辨认。由此，兼顾音韵分解性能和说话人分解性能，可以确保稳定的识别性能，因此可以实现精度高的说话人识别。</p>
  </abstract>
  <abstract id="abstr_eng" date-changed="20091227" lang="eng" format="original">
    <p>The patent refers to the field of 'speech analysis or synthesis and speech recognition'. To realize high-accuracy speaker recognition, a DP matching section(11) determines an optimum matching series(F) which minimizes the sum of phonological distances by using a pitch time series of two characteristic parameter time series(A, B), a speaker-to-speaker distance calculating section determines the sum of the personal distances by using the optimum matching series and the cepstrum coefficient time series of the two characteristic parameter time series(A, B), and an identifying section identifies the speaker on the basis of the sum. So, both phonological resolution and speaker resolution are compatible, and stable recognition performance is ensured, thereby realizing high-accuracy speaker recognition.</p>
  </abstract>
  <legal-data date-changed="20100618">
    <legal-event sequence="1">
      <publication-date>
        <date>20070214</date>
      </publication-date>
      <event-code-1>C06</event-code-1>
      <effect>+</effect>
      <legal-description>PUBLICATION</legal-description>
      <status-identifier>N</status-identifier>
      <docdb-publication-number> CN     1914667A</docdb-publication-number>
    </legal-event>
    <legal-event sequence="2">
      <publication-date>
        <date>20070411</date>
      </publication-date>
      <event-code-1>C10</event-code-1>
      <legal-description>REQUEST OF EXAMINATION AS TO SUBSTANCE</legal-description>
      <status-identifier>N</status-identifier>
      <docdb-publication-number> CN     1914667A</docdb-publication-number>
    </legal-event>
    <legal-event sequence="3">
      <publication-date>
        <date>20100303</date>
      </publication-date>
      <event-code-1>C14</event-code-1>
      <effect>+</effect>
      <legal-description>GRANTED</legal-description>
      <status-identifier>N</status-identifier>
      <docdb-publication-number> CN     1914667A</docdb-publication-number>
    </legal-event>
  </legal-data>
  <description id="descr_chi" lang="chi" format="original" date-changed="20091225">
    <technical-field>
      <p id="p-d0-zh" num="001">技术领域 		 	 	 
            <br /></p>
      <p id="p-d1-zh" num="002">本发明涉及使用声波中包含的个人性信息来识别说话人的说话人识别装 	    	 
            <br />置、程序以及说话人识别方法。 		 	 	 
            <br /></p>
    </technical-field>
    <background-art>
      <p id="p-d2-zh" num="003">背景技术  		  	 
            <br /></p>
      <p id="p-d3-zh" num="004">作为说话人识别装置，提出了一种通过既定内容的语音进行说话人地识 		 	 	 
            <br />别(辨认)的文本依赖型的说话人识别装置，特别提出了一种比较从语音中  		  	 
            <br />提取的特征参数时间序列从而识别说话人的说话人识别装置。	 	 	 	 
            <br /></p>
      <p id="p-d4-zh" num="005">在说话人识别装置中，一般将识别所使用的声波分割为每数毫秒的帧，  		  	 
            <br />对每个该帧求各种音响参数，例如倒谱系数并作为特征参数(语音特征参数)，	 	 	 	 
            <br />使用将其在全部语音区间内作为时间序列的数据来进行说话人识别(说话人 	    	 
            <br />辨认)。 		 	 	 
            <br /></p>
      <p id="p-d5-zh" num="006">特征参数一般在第一意义上包含音韵性信息，在第二意义上包含个人性 	    	 
            <br />信息。在对依赖于个人性信息的说话人识别使用这样的特征参数的情况下， 		 	 	 
            <br />如果不从特征参数中消除音韵性信息则不能确保稳定的识别性能。  		  	 
            <br /></p>
      <p id="p-d6-zh" num="007">因此，在现有的文本依赖型的说话人识别装置中，为了消除音韵性信息， 		 	 	 
            <br />使用将要比较的特征参数时间序列的时间轴非线性缩小比例尺的时间标准化  		  	 
            <br />方法(DP匹配)来计算同一音韵之间的距离(参照非专利文献1)。如图6	 	 	 	 
            <br />所示，进行DP匹配的DP匹配单元200求匹配模式(pattern)(DP路径)， 	    	 
            <br />以使进行比较的两个特征参数时间序列A、B间的距离为最小。此时，在DP 		 	 	 
            <br />匹配的算法上，DP路径被求出，同时最小化距离被计算出。辨认单元201基  		  	 
            <br />于该最小化距离进行说话人的辨认。	 	 	 	 
            <br /></p>
    </background-art>
    <p id="p-d7-zh" num="008">非专利文献1：古井贞熙著“音声情報処理”森北出版株式会社P.91-93  		  	 
            <br />第一版	 	 	 	 
            <br /></p>
    <disclosure>
      <p id="p-d8-zh" num="009">发明内容	 	 	 	 
            <br /></p>
      <p id="p-d9-zh" num="010">但是，由于现有的DP匹配进行要比较的两个特征参数时间序列间的距  		  	 
            <br />离的最小化，因此作为以求说话人的语音的不同为目的的说话人识别的方法 	    	 
            <br />不适当。即，由于过剩的时间伸缩而破坏说话人所特有的单词内的时间构造， 		 	 	 
            <br />作为结果，存在不能将说话人间的差异充分反映在距离上的问题。为了解决  		  	 
            <br />该问题，也进行对时间伸缩设置限制的方法(匹配窗)，但在该方法中，反而	 	 	 	 
            <br />存在发生在同一说话人间进行不同音韵间的对应的危险性的问题。这些问题 	    	 
            <br />由于通过同一计算方法求DP路径的最佳化所使用的距离和用于判别说话人 		 	 	 
            <br />的距离而引起，难以进行精度高的说话人识别。  		  	 
            <br /></p>
      <p id="p-d10-zh" num="011">本发明的目的在于实现精度高的说话人识别。 		 	 	 
            <br /></p>
      <p id="p-d11-zh" num="012">本发明是基于第一语音特征参数时间序列和第二语音特征参数时间序列 	    	 
            <br />的时间序列间的距离，进行说话人的识别的说话人识别装置，其特征在于， 		 	 	 
            <br />所述说话人识别装置包括：设定将所述第一语音特征参数时间序列以及所述  		  	 
            <br />第二语音特征参数时间序列的各语音特征参数相互建立对应的匹配序列，使	 	 	 	 
            <br />用各自的第一语音特征参数组，按照所述匹配序列求各语音特征参数间的第 	    	 
            <br />一距离，并求该第一距离的总和的部件；求最佳匹配序列以使所述第一距离 		 	 	 
            <br />的总和成为最小的部件；使用所述第一语音特征参数时间序列以及所述第二  		  	 
            <br />语音特征参数时间序列各自的第二语音特征参数组，按照所述最佳匹配序列，	 	 	 	 
            <br />求各语音特征参数间的第二距离，并求该第二距离的总和的部件；以及基于 	    	 
            <br />求出的所述第二距离的总和进行说话人的辨认的部件。 		 	 	 
            <br /></p>
      <p id="p-d12-zh" num="013">从另一方面来看，本发明是执行说话人识别功能的计算机可读取的程序， 	    	 
            <br />该说话人识别功能基于第一语音特征参数时间序列和第二语音特征参数时间 		 	 	 
            <br />序列的时间序列间的距离，进行说话人的识别，其特征在于，所述程序使所  		  	 
            <br />述计算机执行以下功能：设定将所述第一语音特征参数时间序列以及所述第	 	 	 	 
            <br />二语音特征参数时间序列的各语音特征参数相互建立对应的匹配序列，使用 	    	 
            <br />各自的第一语音特征参数组，按照所述匹配序列求各语音特征参数间的第一 		 	 	 
            <br />距离，并求该第一距离的总和的功能；求最佳匹配序列以使所述第一距离的  		  	 
            <br />总和成为最小的功能；使用所述第一语音特征参数时间序列以及所述第二语	 	 	 	 
            <br />音特征参数时间序列各自的第二语音特征参数组，按照所述最佳匹配序列， 	    	 
            <br />求各语音特征参数间的第二距离，并求该第二距离的总和的功能；以及基于 		 	 	 
            <br />求出的所述第二距离的总和进行说话人的辨认的功能。  		  	 
            <br /></p>
      <p id="p-d13-zh" num="014">从另一方面来看，本发明是基于第一语音特征参数时间序列和第二语音 		 	 	 
            <br />特征参数时间序列的时间序列间的距离，进行说话人的识别的说话人识别方  		  	 
            <br />法，其特征在于，所述说话人识别装置包括：设定将所述第一语音特征参数 	    	 
            <br />时间序列以及所述第二语音特征参数时间序列的各语音特征参数相互建立对 		 	 	 
            <br />应的匹配序列，使用各自的第一语音特征参数组，按照所述匹配序列求各语  		  	 
            <br />音特征参数间的第一距离，并求该第一距离的总和的步骤；求最佳匹配序列	 	 	 	 
            <br />以使所述第一距离的总和成为最小的步骤；使用所述第一语音特征参数时间 	    	 
            <br />序列以及所述第二语音特征参数时间序列各自的第二语音特征参数组，按照 		 	 	 
            <br />所述最佳匹配序列，求各语音特征参数间的第二距离，并求该第二距离的总  		  	 
            <br />和的步骤；以及基于求出的所述第二距离的总和进行说话人的辨认的步骤。	 	 	 	 
            <br /></p>
    </disclosure>
    <description-of-drawings>
      <p id="p-d14-zh" num="015">附图说明 	    	 
            <br /></p>
      <p id="p-d15-zh" num="016">图1是表示本发明的第一实施方式的说话人识别装置的结构的方框图。	 	 	 	 
            <br /></p>
      <p id="p-d16-zh" num="017">图2是表示本发明的第一实施方式的说话人识别装置具有的说话人辨认  		  	 
            <br />单元的结构的方框图。	 	 	 	 
            <br /></p>
      <p id="p-d17-zh" num="018">图3是表示本发明的第二实施方式的说话人识别装置具有的说话人辨认  		  	 
            <br />单元的结构的方框图。	 	 	 	 
            <br /></p>
      <p id="p-d18-zh" num="019">图4是表示特征参数的结构的示意图。  		  	 
            <br /></p>
      <p id="p-d19-zh" num="020">图5是表示由软件实现本发明的情况下说话人识别装置的结构例的方框 		 	 	 
            <br />图。  		  	 
            <br /></p>
      <p id="p-d20-zh" num="021">图6是表示现有的说话人识别装置的一部分的结构的方框图。 		 	 	 
            <br /></p>
    </description-of-drawings>
    <mode-for-invention>
      <p id="p-d21-zh" num="022">具体实施方式  		  	 
            <br /></p>
      <p id="p-d22-zh" num="023">基于图1以及图2说明本发明的第一实施方式。图1是表示本实施方式 		 	 	 
            <br />的说话人识别装置的结构的方框图，图2是表示说话人识别装置具有的说话  		  	 
            <br />人辨认单元的结构的方框图。本实施方式的说话人识别装置是文本依赖型的	 	 	 	 
            <br />说话人识别装置的一例。 	    	 
            <br /></p>
      <p id="p-d23-zh" num="024">如图1所示，说话人识别装置100包括麦克风1、低通滤波器2、A/D转	 	 	 	 
            <br />换单元3、特征参数生成单元4、说话人辨认单元5、说话人模型生成单元6 	    	 
            <br />以及存储单元7。 		 	 	 
            <br /></p>
      <p id="p-d24-zh" num="025">麦克风1是将被输入了的语音变换为电模拟信号的变换单元。低通滤波 	    	 
            <br />器2是从被输入的模拟信号中截断规定频率以上的频率并输出的滤波器。A/D 		 	 	 
            <br />转换单元3是将被输入的模拟信号用规定的采样频率、量化位数变换为数字  		  	 
            <br />信号的变换单元。通过这些麦克风1、低通滤波器2、A/D转换单元3构成用 	    	 
            <br />于输入语音的语音输入部件。 		 	 	 
            <br /></p>
      <p id="p-d25-zh" num="026">特征参数生成单元4是从被输入了的数字信号中依次提取包含个人性信 	    	 
            <br />息的特征参数，并生成特征参数时间序列(特征矢量列)后输出的生成输出 		 	 	 
            <br />单元。在本实施方式中，特征参数生成单元4对有声区间的声波进行帧分析，  		  	 
            <br />从而求Δ间距以及16次倒谱系数，生成由Δ间距时间序列以及16次倒谱系	 	 	 	 
            <br />数时间序列构成的特征参数时间序列。另外，倒谱系数时间序列的次数不限 	    	 
            <br />定为16次。 		 	 	 
            <br /></p>
      <p id="p-d26-zh" num="027">说话人模型生成单元6是根据由特征参数生成单元4生成的特征参数时 	    	 
            <br />间序列和注册说话人的ID来生成说话人模型的生成单元。存储单元7是存储 		 	 	 
            <br />(注册)由说话人模型生成单元6生成的说话人模型的存储单元。在本实施  		  	 
            <br />方式中，说话人模型被预先注册在存储单元7中。	 	 	 	 
            <br /></p>
      <p id="p-d27-zh" num="028">说话人辨认单元5计算由特征参数生成单元4生成的特征参数时间序列  		  	 
            <br />和预先注册在存储单元7中的说话人模型的距离，基于该距离进行说话人的	 	 	 	 
            <br />辨认，并将该辨认结果作为说话人识别结果输出。 	    	 
            <br /></p>
      <p id="p-d28-zh" num="029">这样的说话人辨认单元5如图2所示，包括DP匹配单元11、说话人之	 	 	 	 
            <br />间距离计算单元12以及辨认单元13。由这些各单元执行各种部件(或步骤)。 	    	 
            <br /></p>
      <p id="p-d29-zh" num="030">对DP匹配单元11以及说话人之间距离计算单元12分别输入特征参数	 	 	 	 
            <br />时间序列A、B。特征参数时间序列A、B包含Δ间距时间序列。另外，在本 	    	 
            <br />实施方式中，特征参数时间序列A是根据从麦克风1输入的声波而生成的特 		 	 	 
            <br />征数据，特征参数时间序列B是注册在存储单元7中的说话人模型的特征数  		  	 
            <br />据。这里，特征参数时间序列A是第一语音特征参数时间序列，特征参数时	 	 	 	 
            <br />间序列B是第二语音特征参数时间序列。下面表示这样的特征参数时间序列 	    	 
            <br />A、B。 		 	 	 
            <br /></p>
      <p id="p-d30-zh" num="031">特征参数时间序列 	    	 
            <br /></p>
      <p id="p-d31-zh" num="032">A＝α<sub>1</sub>，α<sub>2</sub>，…，α<sub>i</sub>，…，α<sub>I</sub><br /></p>
      <p id="p-d32-zh" num="033">B＝β<sub>1</sub>，β<sub>2</sub>，…，β<sub>j</sub>，…，β<sub>J</sub><br /></p>
      <p id="p-d33-zh" num="034">特征数据 		 	 	 
            <br /></p>
      <p id="p-d34-zh" num="035">α<sub>i</sub>＝p<sub>i</sub>，α<sub>i1</sub>，α<sub>i2</sub>，…，α<sub>ik</sub>，…，α<sub>i16</sub><br /></p>
      <p id="p-d35-zh" num="036">β<sub>j</sub>＝q<sub>j</sub>，β<sub>j1</sub>，β<sub>j2</sub>，…，β<sub>jk</sub>，…，β<sub>j16</sub><br /></p>
      <p id="p-d36-zh" num="037">特征参数α<sub>i</sub>，β<sub>j</sub>是对有声区间的声波进行帧分析而得到的Δ间距(p<sub>i</sub>，q<sub>j</sub>)	 	 	 	 
            <br />和16次倒谱系数(α<sub>i1</sub>～α<sub>i16</sub>，β<sub>j1</sub>～β<sub>j16</sub>)构成。从而，特征参数时间序列A、 	    	 
            <br />B由Δ间距时间序列和16次倒谱系数时间序列构成。这里，相对地Δ间距包 		 	 	 
            <br />含较多的音韵性信息，倒谱系数包含较多的个人性信息。  		  	 
            <br /></p>
      <p id="p-d37-zh" num="038">DP匹配单元11进行DP匹配处理，以便两个特征参数时间序列A、B的 		 	 	 
            <br />音韵之间对应。此时，通过DP匹配算法进行最佳化，以便作为第一距离的  		  	 
            <br />音韵性距离d(i，j)的总和D(F)为最小，并求最佳匹配序列F。	 	 	 	 
            <br /></p>
      <p id="p-d38-zh" num="039">这里，最佳匹配序列F作为时间对应因子c<sub>n</sub>的序列如式(1)这样被定  		  	 
            <br />义，各特征参数间的音韵性距离d(i，j)使用Δ间距如下述式(1)这样被定	 	 	 	 
            <br />义，总和D(F)如下述式(3)这样被定义。即，最佳匹配序列F、音韵性 	    	 
            <br />距离d(i，j)及其总和D(F)分别通过下述式(1)、式(2)以及式(3)被 		 	 	 
            <br />求出。  		  	 
            <br /></p>
      <p id="p-d39-zh" num="040">[算式1] 		 	 	 
            <br /></p>
      <p id="p-d40-zh" num="041">F＝c<sub>1</sub>，c<sub>2</sub>，---，c<sub>n</sub>，---，c<sub>N</sub>，c<sub>n</sub>＝(i<sub>n</sub>，j<sub>n</sub>)  ····(1) 	    	 
            <br /></p>
      <p id="p-d41-zh" num="042">[算式2]	 	 	 	 
            <br /></p>
      <p id="p-d42-zh" num="043">d(i，j)＝|p<sub>i</sub>-q<sub>j</sub>|                                  ····(2)  		  	 
            <br /></p>
      <p id="p-d43-zh" num="044">[算式3] 		 	 	 
            <br /></p>
      <p id="p-d44-zh" num="045">
        <br />
      </p>
      <p id="p-d45-zh" num="046">如详细叙述，DP匹配单元11使用两个特征参数时间序列A、B的各自 	    	 
            <br />的Δ间距时间序列，通过式(2)来求音韵性距离d(i，j)，并通过式(3)求 		 	 	 
            <br />其总和D(F)。此时，通过式(3)以及式(1)进行最佳化，以使总和D(F)  		  	 
            <br />为最小，从而求最佳匹配序列F。这里，Δ间距时间序列是第一语音特征参	 	 	 	 
            <br />数组。 	    	 
            <br /></p>
      <p id="p-d46-zh" num="047">说话人之间距离计算单元12使用由DP匹配单元11求出的最佳匹配序	 	 	 	 
            <br />列F，计算作为第二距离的个人性距离e(i，j)的总和E(F)。这里，个人性 	    	 
            <br />距离e(i，j)如下述式(4)这样被定义，总和E(F)如下述式(5)这样被 		 	 	 
            <br />定义。即，个人性距离e(i，j)及其总和E(F)分别通过下述式(4)以及式  		  	 
            <br />(5)被求出。	 	 	 	 
            <br /></p>
      <p id="p-d47-zh" num="048">[算式4]  		  	 
            <br /></p>
      <p id="p-d48-zh" num="049">
        <br />
      </p>
      <p id="p-d49-zh" num="050">[算式5]  		  	 
            <br /></p>
      <p id="p-d50-zh" num="051">
        <br />
      </p>
      <p id="p-d51-zh" num="052">如详细叙述，说话人之间距离计算单元12使用两个特征参数时间序列 		 	 	 
            <br />A、B的各自的倒谱系数时间序列，通过式(4)来求个人性距离e(i，j)，并  		  	 
            <br />基于最佳匹配序列F，通过式(5)求其总和E(F)。在本实施方式中，作为	 	 	 	 
            <br />倒谱系数时间序列，使用1～16次的倒谱系数时间序列。另外，倒谱系数时 	    	 
            <br />间序列是第二语音特征参数组。 		 	 	 
            <br /></p>
      <p id="p-d52-zh" num="053">辨认单元13基于由说话人之间距离计算单元12求出的个人性距离的总 	    	 
            <br />和E(F)进行说话人的辨认，并将其辨认结果作为说话人识别结果输出。这 		 	 	 
            <br />里，例如将总和E(F)与阈值进行比较，进行说话人辨认的判定(说话人对  		  	 
            <br />照)。	 	 	 	 
            <br /></p>
      <p id="p-d53-zh" num="054">这样，根据本实施方式，使用两个特征参数时间序列A、B的各自的Δ  		  	 
            <br />间距时间序列来求音韵性距离的总和D(F)为最小的最佳间距序列F，使用	 	 	 	 
            <br />该最佳匹配序列和两个特征参数时间序列A、B的各自的倒谱系数时间序列 	    	 
            <br />求个人性距离的总和E(F)，基于该总和E(F)进行说话人的辨认。由此， 		 	 	 
            <br />将语音特征参数时间序列A、B匹配时的音韵分解性能和求语音特征参数时  		  	 
            <br />间序列间的距离时的说话人分解性能并存，可以确保稳定的识别性能，因此	 	 	 	 
            <br />可以实现精度高的说话人识别。此外，DP路径的最佳化所使用的距离和用于 	    	 
            <br />判别说话人的距离用不同的方法被求出，因此可以将说话人间的差异充分地 		 	 	 
            <br />反映到距离上，此外由于可以在同一说话人间抑制不同音韵间的对应，所以  		  	 
            <br />可以实现精度高的说话人识别。	 	 	 	 
            <br /></p>
      <p id="p-d54-zh" num="055">这里，在音韵性距离和个人性距离所使用的特征参数互相独立的情况下，  		  	 
            <br />在特征参数的变化量多的部位发生匹配偏离(时间偏离)的可能性高。在该	 	 	 	 
            <br />情况下，如下述式(6)所示这样，将音韵性距离e(i，j)如下述式(6)这 	    	 
            <br />样变形来施加稍微的“平均”作用，从而可以改善匹配偏离。 		 	 	 
            <br /></p>
      <p id="p-d55-zh" num="056">[算式6] 	    	 
            <br /></p>
      <p id="p-d56-zh" num="057">
        <br />
      </p>
      <p id="p-d57-zh" num="058">                                ····(6) 	    	 
            <br /></p>
      <p id="p-d58-zh" num="059">此外，通过相互进行上述“平均”作用，可以得到更稳定的音韵性距离。	 	 	 	 
            <br />在该情况下，将音韵性距离e(i，j)如下述式(7)这样变形。 	    	 
            <br /></p>
      <p id="p-d59-zh" num="060">平均距离被定义为双方的相加平均。	 	 	 	 
            <br /></p>
      <p id="p-d60-zh" num="061">[算式7]  		  	 
            <br /></p>
      <p id="p-d61-zh" num="062">
        <br />
      </p>
      <p id="p-d62-zh" num="063">
        <br />
      </p>
      <p id="p-d63-zh" num="064">                                ····(7) 		 	 	 
            <br /></p>
      <p id="p-d64-zh" num="065">在本实施方式中，作为第一语音特征参数时间序列的特征参数时间序列 	    	 
            <br />A以及作为第二语音特征参数时间序列的特征参数时间序列B包括从语音的 		 	 	 
            <br />基本频率得到的基本频率信息时间序列，以及从声道的共鸣信息得到的共鸣  		  	 
            <br />信息时间序列，第一语音特征参数组是基本频率信息时间序列，第二语音特	 	 	 	 
            <br />征参数组是共鸣信息时间序列，因此可以可靠地实现高精度的说话人识别。 	    	 
            <br /></p>
      <p id="p-d65-zh" num="066">在本实施方式中，特征参数时间序列A以及特征参数时间序列B包括从	 	 	 	 
            <br />语音的抑扬信息得到的Δ间距时间序列，以及从声道的共鸣信息得到的倒谱 	    	 
            <br />系数时间序列，作为第一距离的音韵性距离d以及作为第二距离的个人性距 		 	 	 
            <br />离e通过  		  	 
            <br /></p>
      <p id="p-d66-zh" num="067">[算式8] 		 	 	 
            <br /></p>
      <p id="p-d67-zh" num="068">d＝|p<sub>k</sub>-q<sub>k</sub>| 	    	 
            <br /></p>
      <p id="p-d68-zh" num="069">
        <br />
      </p>
      <p id="p-d69-zh" num="070">k0≥1	 	 	 	 
            <br /></p>
      <p id="p-d70-zh" num="071">d，e：第一距离、第二距离  		  	 
            <br /></p>
      <p id="p-d71-zh" num="072">p：第一语音特征参数时间序列的Δ间距 		 	 	 
            <br /></p>
      <p id="p-d72-zh" num="073">q：第二语音特征参数时间序列的Δ间距 	    	 
            <br /></p>
      <p id="p-d73-zh" num="074">a<sub>k</sub>：第一语音特征参数时间序列的倒谱系数 	    	 
            <br /></p>
      <p id="p-d74-zh" num="075">b<sub>k</sub>：第二语音特征参数时间序列的倒谱系数	 	 	 	 
            <br /></p>
      <p id="p-d75-zh" num="076">k：倒谱次数  		  	 
            <br /></p>
      <p id="p-d76-zh" num="077">而被求出，因此可以更可靠地实现精度高的说话人识别。 		 	 	 
            <br /></p>
      <p id="p-d77-zh" num="078">在本实施方式中，特征参数时间序列A的第i个特征参数α<sub>i</sub>和特征参数 	    	 
            <br />时间序列B的第j个特征参数β<sub>j</sub>的个人性距离e(i，j)通过 		 	 	 
            <br /></p>
      <p id="p-d78-zh" num="079">[算式9] 	    	 
            <br /></p>
      <p id="p-d79-zh" num="080">
        <br />
      </p>
      <p id="p-d80-zh" num="081">dist(X，Y)：语音特征参数X和Y的距离	 	 	 	 
            <br /></p>
      <p id="p-d81-zh" num="082">L：平均宽度(＞0)  		  	 
            <br /></p>
      <p id="p-d82-zh" num="083">而被求出，因此可以改善匹配偏离。 		 	 	 
            <br /></p>
      <p id="p-d83-zh" num="084">此外，特征参数时间序列A的第i个特征参数α<sub>i</sub>和特征参数时间序列B 	    	 
            <br />的第j个特征参数β<sub>j</sub>的个人性距离e(i，j)通过 		 	 	 
            <br /></p>
      <p id="p-d84-zh" num="085">[算式10] 	    	 
            <br /></p>
      <p id="p-d85-zh" num="086">
        <br />
      </p>
      <p id="p-d86-zh" num="087">dist(X，Y)：语音特征参数X和Y的距离	 	 	 	 
            <br /></p>
      <p id="p-d87-zh" num="088">L：平均宽度(＞0)  		  	 
            <br /></p>
      <p id="p-d88-zh" num="089">而被求出时，可以得到更稳定的音韵性距离。 		 	 	 
            <br /></p>
      <p id="p-d89-zh" num="090">基于图3以及图4说明本发明的第二实施方式。图3是表示本实施方式 	    	 
            <br />的说话人识别装置具有的说话人辨认单元的结构的方框图，图4是表示特征 		 	 	 
            <br />参数的结构的示意图。  		  	 
            <br /></p>
      <p id="p-d90-zh" num="091">本实施方式是第一实施方式所示的说话人辨认单元5的变形例。另外， 		 	 	 
            <br />与所述第一实施方式相同的部分用相同符号表示，说话人辨认单元5以外的  		  	 
            <br />说明省略。此外，在本实施方式中，特征参数生成单元4对有声区间的声波 	    	 
            <br />进行帧分析来求16次倒谱系数，生成由16次倒谱系数构成的特征参数时间 		 	 	 
            <br />序列。另外，倒谱系数时间序列的次数不限定于16次。  		  	 
            <br /></p>
      <p id="p-d91-zh" num="092">如图3所示，说话人辨认单元5基本上与第一实施方式同样，包括DP 		 	 	 
            <br />匹配单元11、说话人之间距离计算单元12以及辨认单元13。由这些各单元  		  	 
            <br />执行各种部件(或步骤)。	 	 	 	 
            <br /></p>
      <p id="p-d92-zh" num="093">对DP匹配单元11以及说话人之间距离计算单元12分别输入特征参数  		  	 
            <br />时间序列A、B。另外，在本实施方式中，特征参数时间序列A是根据从麦	 	 	 	 
            <br />克风1输入的声波而生成的特征数据，特征参数时间序列B是注册在存储单 	    	 
            <br />元7中的说话人模型的特征数据。这里，特征参数时间序列A是第一语音特 		 	 	 
            <br />征参数时间序列，特征参数时间序列B是第二语音特征参数时间序列。下面  		  	 
            <br />表示这样的特征参数时间序列A、B。	 	 	 	 
            <br /></p>
      <p id="p-d93-zh" num="094">特征参数时间序列  		  	 
            <br /></p>
      <p id="p-d94-zh" num="095">A＝α<sub>1</sub>，α<sub>2</sub>，…，α<sub>i</sub>，…，α<sub>I</sub><br /></p>
      <p id="p-d95-zh" num="096">B＝β<sub>1</sub>，β<sub>2</sub>，…，β<sub>j</sub>，…，β<sub>J</sub><br /></p>
      <p id="p-d96-zh" num="097">特征数据	 	 	 	 
            <br /></p>
      <p id="p-d97-zh" num="098">α<sub>i</sub>＝α<sub>i1</sub>，α<sub>i2</sub>，…，α<sub>ik</sub>，…，α<sub>i16</sub><br /></p>
      <p id="p-d98-zh" num="099">β<sub>j</sub>＝β<sub>j1</sub>，β<sub>j2</sub>，…，β<sub>jk</sub>，…，β<sub>j16</sub><br /></p>
      <p id="p-d99-zh" num="100">特征参数α<sub>i</sub>，β<sub>j</sub>是对有声区间的声波进行帧分析而得到的由16次倒谱系 	    	 
            <br />数(α<sub>i1</sub>～α<sub>i16</sub>，β<sub>j1</sub>～β<sub>j16</sub>)构成。从而，特征参数时间序列A、B是16次倒谱 		 	 	 
            <br />系数的时间序列。另外，这里，1～8次的倒谱系数时间序列是低次的倒谱系  		  	 
            <br />数时间序列，m～16(m＞8)次的倒谱系数时间序列是高次的倒谱系数时间序	 	 	 	 
            <br />列。 	    	 
            <br /></p>
      <p id="p-d100-zh" num="101">DP匹配单元11进行DP匹配处理，以便两个特征参数时间序列A、B的	 	 	 	 
            <br />音韵之间对应。此时，通过DP匹配算法进行最佳化，以便作为第一距离的 	    	 
            <br />音韵性距离d(i，j)的总和D(F)为最小，并求最佳匹配序列F。 		 	 	 
            <br /></p>
      <p id="p-d101-zh" num="102">这里，最佳匹配序列F作为时间对应因子c<sub>n</sub>的序列如式(1)这样被定 	    	 
            <br />义，各特征参数间的音韵性距离d(i，j)使用低次的倒谱系数如下述式(8) 		 	 	 
            <br />这样被定义，总和D(F)如下述式(3)这样被定义。即，最佳匹配序列F、  		  	 
            <br />音韵性距离d(i，j)及其总和D(F)分别通过下述式(1)、式(8)以及式	 	 	 	 
            <br />(3)被求出。 		 	 	 
            <br /></p>
      <p id="p-d102-zh" num="103">[算式11] 	    	 
            <br /></p>
      <p id="p-d103-zh" num="104">F＝c<sub>1</sub>，c<sub>2</sub>，---，c<sub>n</sub>，---，c<sub>N</sub>，c<sub>n</sub>＝(i<sub>n</sub>，j<sub>n</sub>)    ····(1)	 	 	 	 
            <br /></p>
      <p id="p-d104-zh" num="105">[算式12]  		  	 
            <br /></p>
      <p id="p-d105-zh" num="106">
        <br />
      </p>
      <p id="p-d106-zh" num="107">[算式13] 		 	 	 
            <br /></p>
      <p id="p-d107-zh" num="108">
        <br />
      </p>
      <p id="p-d108-zh" num="109">如详细叙述，DP匹配单元11使用两个特征参数时间序列A、B的各自 	    	 
            <br />的低次的倒谱系数时间序列(1～8的倒谱系数时间序列)，通过式(8)来求 		 	 	 
            <br />音韵性距离d(i，j)，并通过式(3)求其总和D(F)。此时，通过式(3)以  		  	 
            <br />及式(1)进行最佳化，以使总和D(F)为最小，从而求最佳匹配序列F。	 	 	 	 
            <br />这里，低次的倒谱系数时间序列是第一语音特征参数组。 	    	 
            <br /></p>
      <p id="p-d109-zh" num="110">说话人之间距离计算单元12使用由DP匹配单元11求出的最佳匹配序	 	 	 	 
            <br />列F，计算作为个人性距离e(i，j)的总和E(F)。这里，个人性距离e(i，j) 	    	 
            <br />如下述式(4)这样被定义，总和E(F)如下述式(5)这样被定义。即，个 		 	 	 
            <br />人性距离e(i，j)及其总和E(F)分别通过下述式(4)以及式(5)被求出。  		  	 
            <br /></p>
      <p id="p-d110-zh" num="111">[算式14] 		 	 	 
            <br /></p>
      <p id="p-d111-zh" num="112">
        <br />
      </p>
      <p id="p-d112-zh" num="113">[算式15] 	    	 
            <br /></p>
      <p id="p-d113-zh" num="114">
        <br />
      </p>
      <p id="p-d114-zh" num="115">如详细叙述，说话人之间距离计算单元12使用包含两个特征参数时间序	 	 	 	 
            <br />列A、B的各自的高次的倒谱系数时间序列(m～16(m＞8)次的倒谱系数时 	    	 
            <br />间序列)的倒谱系数时间序列，通过式(4)来求个人性距离e(i，j)，并基 		 	 	 
            <br />于最佳匹配序列F，通过式(5)求其总和E(F)。在本实施方式中，作为倒  		  	 
            <br />谱系数时间序列，使用1～16次的倒谱系数时间序列。这里，高次的倒谱系 	    	 
            <br />数一般比低次的倒谱系数包含更多的个人性信息。另外，倒谱系数时间序列 		 	 	 
            <br />是第二语音特征参数组。  		  	 
            <br /></p>
      <p id="p-d115-zh" num="116">这里，如图4所示，在具有1～N次的倒谱系数的特征参数中，在将1～ 		 	 	 
            <br />n次的倒谱系数作为低次的倒谱系数(图4(a)中斜线部分)的情况下，高  		  	 
            <br />次的倒谱系数是m～N(m＞n)次的倒谱系数。该高次的倒谱系数被时间序列	 	 	 	 
            <br />化的序列是高次的倒谱系数时间序列。从而，包含高次的倒谱系数时间序列 	    	 
            <br />的倒谱系数时间序列也可以是仅由m～N(m＞n)次的倒谱系数(图4(b) 		 	 	 
            <br />中网线部分)构成的时间序列，或者也可以是由m～N(m＞n)次的倒谱系数  		  	 
            <br />以及低次的倒谱系数的一部分(图4(c)中网线部分)构成的时间序列，进	 	 	 	 
            <br />而也可以是由1～N次的倒谱系数(图4(d)中网线部分)构成的时间序列。 	    	 
            <br />另外，在本实施方式中，设定为N＝16以及n＝8，但不限于此。 		 	 	 
            <br /></p>
      <p id="p-d116-zh" num="117">辨认单元13基于由说话人之间距离计算单元12求出的个人性距离的总 	    	 
            <br />和E(F)进行说话人的辨认，并将其辨认结果作为说话人识别结果输出。这 		 	 	 
            <br />里，例如将总和E(F)与阈值进行比较，进行说话人辨认的判定(说话人对  		  	 
            <br />照)。	 	 	 	 
            <br /></p>
      <p id="p-d117-zh" num="118">这样，根据本实施方式，使用两个特征参数时间序列A、B的各自的低  		  	 
            <br />次的倒谱系数时间序列来求音韵性距离的总和D(F)为最小的最佳间距序列	 	 	 	 
            <br />F，使用该最佳匹配序列和包含两个特征参数时间序列A、B的各自的高次的 	    	 
            <br />倒谱系数时间序列的倒谱系数时间序列求个人性距离的总和E(F)，基于该 		 	 	 
            <br />总和E(F)进行说话人的辨认。由此，将语音特征参数时间序列A、B匹配  		  	 
            <br />时的音韵分辩性能和求语音特征参数时间序列间的距离时的说话人分辨性能	 	 	 	 
            <br />并存，可以确保稳定的识别性能，因此可以实现精度高的说话人识别。此外， 	    	 
            <br />DP路径的最佳化所使用的距离和用于判别说话人的距离用不同的方法被求 		 	 	 
            <br />出，因此可以将说话人间的差异充分地反映到距离上，此外由于可以在同一  		  	 
            <br />说话人间抑制不同音韵间的对应，所以可以实现精度高的说话人识别。	 	 	 	 
            <br /></p>
      <p id="p-d118-zh" num="119">在本实施方式中，作为第一语音特征参数时间序列的特征参数时间序列  		  	 
            <br />A以及作为第二语音特征参数时间序列的特征参数时间序列B是从声道的共	 	 	 	 
            <br />鸣信息得到的倒谱系数时间序列，第一语音特征参数组是倒谱系数时间序列 	    	 
            <br />中的低次的倒谱系数时间序列，第二语音特征参数组是包含倒谱系数时间序 		 	 	 
            <br />列中的高次的倒谱系数时间序列的倒谱系数时间序列，因此可以可靠地实现  		  	 
            <br />高精度的说话人识别。 	    	 
            <br /></p>
      <p id="p-d119-zh" num="120">在本实施方式中，作为第一语音特征参数时间序列的特征参数时间序列	 	 	 	 
            <br />A以及作为第二语音特征参数时间序列的特征参数时间序列B是从声道的共 	    	 
            <br />鸣信息得到的倒谱系数时间序列，作为第一距离的音韵性距离d以及作为第 		 	 	 
            <br />二距离的个人性距离e通过  		  	 
            <br /></p>
      <p id="p-d120-zh" num="121">[算式16] 		 	 	 
            <br /></p>
      <p id="p-d121-zh" num="122">
        <br />
      </p>
      <p id="p-d122-zh" num="123">
        <br />
      </p>
      <p id="p-d123-zh" num="124">N＜M，k0≥1 	    	 
            <br /></p>
      <p id="p-d124-zh" num="125">d，e：第一距离、第二距离	 	 	 	 
            <br /></p>
      <p id="p-d125-zh" num="126">a<sub>k</sub>：第一语音特征参数时间序列的倒谱系数  		  	 
            <br /></p>
      <p id="p-d126-zh" num="127">b<sub>k</sub>：第二语音特征参数时间序列的倒谱系数 		 	 	 
            <br /></p>
      <p id="p-d127-zh" num="128">k：倒谱次数 	    	 
            <br /></p>
      <p id="p-d128-zh" num="129">而被求出，因此可以可靠地实现高精度的说话人识别。	 	 	 	 
            <br /></p>
      <p id="p-d129-zh" num="130">另外，本发明不限定于如前述的实施方式所示的特定的硬件结构，用软  		  	 
            <br />件也可以实现。即，可用软件实现说话人辨认单元5的功能(说话人识别功	 	 	 	 
            <br />能)。图5是表示由软件实现本发明的情况下的说话人识别装置100的结构例 	    	 
            <br />的方框图。 		 	 	 
            <br /></p>
      <p id="p-d130-zh" num="131">如图5所示，说话人识别装置100包括集中控制该说话人识别装置100 	    	 
            <br />的各部分的CPU101，该CPU101上通过总线连接存储了BIOS等的ROM或 		 	 	 
            <br />由可改写地存储各种数据的RAM构成的存储器102，构成微型计算机。此外，  		  	 
            <br />CPU101上经由未图示的I/O总线连接有HDD(Hard Disk Drive，硬盘驱动器)	 	 	 	 
            <br />103、对计算机可读取的存储介质的CD(Compact Disc，光盘)-ROM104 	    	 
            <br />进行读取的CD-ROM驱动器105、主管说话人识别装置100和因特网等的 		 	 	 
            <br />通信的通信装置106、键盘107、CRT或LCD等显示装置108、麦克风1。  		  	 
            <br /></p>
      <p id="p-d131-zh" num="132">CD-ROM104等计算机可读取的存储介质中存储了实现本发明的说话 		 	 	 
            <br />人识别功能的程序，通过将该程序安装在说话人识别装置100中，可以使  		  	 
            <br />CPU101执行本发明的说话人识别功能。此外，从麦克风1输入的语音临时被	 	 	 	 
            <br />存储在HDD103等中。然后，程序被起动时，HDD103等中临时保存的语音 	    	 
            <br />数据被读入，执行说话人识别处理。该说话人识别处理实现与特征参数生成 		 	 	 
            <br />单元4或说话人辨认单元5等各部分同样的功能。由此，可以得到与所述实	 	 	 	 
            <br />施方式的效果同样的效果。 	    	 
            <br /></p>
      <p id="p-d132-zh" num="133">另外，作为存储介质，不仅可以使用CD-ROM104，也可以使用DVD	 	 	 	 
            <br />等各种光盘、各种光磁盘、软盘等各种磁盘、半导体存储器等各种方式的介 	    	 
            <br />质。此外，也可以从因特网等网络下载并安装在HDD103中。在该情况下， 		 	 	 
            <br />作为发送端的服务器中存储了程序的存储装置也成为本发明的存储介质。另  		  	 
            <br />外，程序可以是在规定的OS(Operating System，操作系统)上动作的程序，	 	 	 	 
            <br />在该情况下，也可以是将后述的各处理的一部分的执行转移到OS的程序， 	    	 
            <br />也可以是作为文字处理软件等规定的应用软件或构成OS等的一组程序文件 		 	 	 
            <br />的一部分而包含的程序。  		  	 
            <br /></p>
    </mode-for-invention>
  </description>
  <claims id="claims_chi" lang="chi" format="original" date-changed="20091225">
    <claim num="1">
      <claim-text>
        <claim-text>1.一种说话人识别装置，基于第一语音特征参数时间序列和第二语音特征  		  	 
                <br />参数时间序列的时间序列间的距离，进行说话人的识别，其特征在于，所述	 	 	 	 
                <br />说话人识别装置包括： 	    	 
                <br /></claim-text>
        <claim-text>设定使所述第一语音特征参数时间序列以及所述第二语音特征参数时间	 	 	 	 
                <br />序列的各语音特征参数相互建立对应的匹配序列，使用各自的第一语音特征 	    	 
                <br />参数组，按照所述匹配序列求各语音特征参数间的第一距离，并求该第一距 		 	 	 
                <br />离的总和的部件；  		  	 
                <br /></claim-text>
        <claim-text>求最佳匹配序列以使所述第一距离的总和成为最小的部件； 		 	 	 
                <br /></claim-text>
        <claim-text>使用所述第一语音特征参数时间序列以及所述第二语音特征参数时间序 	    	 
                <br />列各自的第二语音特征参数组，按照所述最佳匹配序列，求各语音特征参数 		 	 	 
                <br />间的第二距离，并求该第二距离的总和的部件；以及  		  	 
                <br /></claim-text>
        <claim-text>基于求出的所述第二距离的总和进行说话人的辨认的部件。 		 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="2">
      <claim-text>
        <claim-text>2.如权利要求1所述的说话人识别装置，其特征在于，  		  	 
                <br /></claim-text>
        <claim-text>所述第一语音特征参数时间序列以及所述第二语音特征参数时间序列包 		 	 	 
                <br />括从语音的基本频率得到的基本频率信息时间序列，以及从声道的共鸣信息  		  	 
                <br />得到的共鸣信息时间序列，	 	 	 	 
                <br /></claim-text>
        <claim-text>所述第一语音特征参数组是所述基本频率信息时间序列，  		  	 
                <br /></claim-text>
        <claim-text>所述第二语音特征参数组是所述共鸣信息时间序列。 		 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="3">
      <claim-text>
        <claim-text>3.如权利要求1所述的说话人识别装置，其特征在于，  		  	 
                <br /></claim-text>
        <claim-text>所述第一语音特征参数时间序列以及所述第二语音特征参数时间序列是 		 	 	 
                <br />从声道的共鸣信息得到的倒谱系数时间序列，  		  	 
                <br /></claim-text>
        <claim-text>所述第一语音特征参数组是所述倒谱系数时间序列中的低次的倒谱系数 		 	 	 
                <br />时间序列，  		  	 
                <br /></claim-text>
        <claim-text>所述第二语音特征参数组是包含所述倒谱系数时间序列中的高次的倒谱 		 	 	 
                <br />系数时间序列的倒谱系数时间序列。  		  	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="4">
      <claim-text>
        <claim-text>4.如权利要求1所述的说话人识别装置，其特征在于，	 	 	 	 
                <br /></claim-text>
        <claim-text>所述第一语音特征参数时间序列以及所述第二语音特征参数时间序列包  		  	 
                <br />括从语音的抑扬信息得到的Δ间距时间序列，以及从声道的共鸣信息得到的	 	 	 	 
                <br />倒谱系数时间序列， 	    	 
                <br /></claim-text>
        <claim-text>所述第一距离d以及所述第二距离e通过 	    	 
                <br /></claim-text>
        <claim-text>[算式1]	 	 	 	 
                <br /></claim-text>
        <claim-text>                   d＝|p<sub>k</sub>-q<sub>k</sub>|  		  	 
                <br /></claim-text>
        <claim-text>
          <br />
        </claim-text>
        <claim-text>k0≥1 		 	 	 
                <br /></claim-text>
        <claim-text>d，e：第一距离、第二距离 	    	 
                <br /></claim-text>
        <claim-text>p：第一语音特征参数时间序列的Δ间距	 	 	 	 
                <br /></claim-text>
        <claim-text>q：第二语音特征参数时间序列的Δ间距  		  	 
                <br /></claim-text>
        <claim-text>a<sub>k</sub>：第一语音特征参数时间序列的倒谱系数 		 	 	 
                <br /></claim-text>
        <claim-text>b<sub>k</sub>：第二语音特征参数时间序列的倒谱系数 	    	 
                <br /></claim-text>
        <claim-text>k：倒谱次数	 	 	 	 
                <br />而被求出。 	    	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="5">
      <claim-text>
        <claim-text>5.如权利要求1所述的说话人识别装置，其特征在于， 		 	 	 
                <br /></claim-text>
        <claim-text>所述第一语音特征参数时间序列的第i个语音特征参数和所述第二语音 	    	 
                <br />特征参数时间序列的第j个语音特征参数的所述第二距离e(i，j)通过 		 	 	 
                <br /></claim-text>
        <claim-text>[算式2] 	    	 
                <br /></claim-text>
        <claim-text>
          <br />
        </claim-text>
        <claim-text>dist(X，Y)：语音特征参数X和Y的距离	 	 	 	 
                <br /></claim-text>
        <claim-text>L：平均宽度(＞0)  		  	 
                <br />而被求出。	 	 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="6">
      <claim-text>
        <claim-text>6.如权利要求1所述的说话人识别装置，其特征在于， 	    	 
                <br /></claim-text>
        <claim-text>所述第一语音特征参数时间序列的第i个语音特征参数和所述第二语音	 	 	 	 
                <br />特征参数时间序列的第j个语音特征参数的所述第二距离e(i，j)通过 	    	 
                <br /></claim-text>
        <claim-text>[算式3]	 	 	 	 
                <br /></claim-text>
        <claim-text>
          <br />
        </claim-text>
        <claim-text>dist(X，Y)：语音特征参数X和Y的距离	 	 	 	 
                <br /></claim-text>
        <claim-text>L：平均宽度(＞0)  		  	 
                <br />而被求出。	 	 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="7">
      <claim-text>
        <claim-text>7.如权利要求1所述的说话人识别装置，其特征在于， 	    	 
                <br /></claim-text>
        <claim-text>所述第一语音特征参数时间序列以及所述第二语音特征参数时间序列是	 	 	 	 
                <br />从声道的共鸣信息得到的倒谱系数时间序列， 	    	 
                <br /></claim-text>
        <claim-text>所述第一距离d以及所述第二距离通过	 	 	 	 
                <br /></claim-text>
        <claim-text>[算式4]  		  	 
                <br /></claim-text>
        <claim-text>
          <br />
        </claim-text>
        <claim-text>
          <br />
        </claim-text>
        <claim-text>N＜M，k0≥1 		 	 	 
                <br /></claim-text>
        <claim-text>d，e：第一距离、第二距离 	    	 
                <br /></claim-text>
        <claim-text>a<sub>k</sub>：第一语音特征参数时间序列的倒谱系数	 	 	 	 
                <br /></claim-text>
        <claim-text>b<sub>k</sub>：第一语音特征参数时间序列的倒谱系数  		  	 
                <br /></claim-text>
        <claim-text>k：倒谱次数 		 	 	 
                <br />而被求出。  		  	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="8">
      <claim-text>
        <claim-text>8.一种程序，是执行说话人识别功能的计算机可读取的程序，该说话人识	 	 	 	 
                <br />别功能基于第一语音特征参数时间序列和第二语音特征参数时间序列的时间 	    	 
                <br />序列间的距离，进行说话人的识别，其特征在于，所述程序使所述计算机执 		 	 	 
                <br />行以下功能：  		  	 
                <br /></claim-text>
        <claim-text>设定使所述第一语音特征参数时间序列以及所述第二语音特征参数时间 		 	 	 
                <br />序列的各语音特征参数相互建立对应的匹配序列，使用各自的第一语音特征  		  	 
                <br />参数组，按照所述匹配序列求各语音特征参数间的第一距离，并求该第一距	 	 	 	 
                <br />离的总和的功能； 		 	 	 
                <br /></claim-text>
        <claim-text>求最佳匹配序列以使所述第一距离的总和成为最小的功能； 	    	 
                <br /></claim-text>
        <claim-text>使用所述第一语音特征参数时间序列以及所述第二语音特征参数时间序	 	 	 	 
                <br />列各自的第二语音特征参数组，按照所述最佳匹配序列，求各语音特征参数 	    	 
                <br />间的第二距离，并求该第二距离的总和的功能；以及 		 	 	 
                <br /></claim-text>
        <claim-text>基于求出的所述第二距离的总和进行说话人的辨认的功能。 	    	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="9">
      <claim-text>
        <claim-text>9.一种说话人识别方法，基于第一语音特征参数时间序列和第二语音特征 		 	 	 
                <br />参数时间序列的时间序列间的距离，进行说话人的识别，其特征在于，所述  		  	 
                <br />说话人识别装置包括：	 	 	 	 
                <br /></claim-text>
        <claim-text>设定将所述第一语音特征参数时间序列以及所述第二语音特征参数时间  		  	 
                <br />序列的各语音特征参数相互建立对应的匹配序列，使用各自的第一语音特征	 	 	 	 
                <br />参数组，按照所述匹配序列求各语音特征参数间的第一距离，并求该第一距 	    	 
                <br />离的总和的步骤； 		 	 	 
                <br /></claim-text>
        <claim-text>求最佳匹配序列以使所述第一距离的总和成为最小的步骤； 	    	 
                <br /></claim-text>
        <claim-text>使用所述第一语音特征参数时间序列以及所述第二语音特征参数时间序	 	 	 	 
                <br />列各自的第二语音特征参数组，按照所述最佳匹配序列，求各语音特征参数 	    	 
                <br />间的第二距离，并求该第二距离的总和的步骤；以及 		 	 	 
                <br /></claim-text>
        <claim-text>基于求出的所述第二距离的总和进行说话人的辨认的步骤。 	    	 
                <br /></claim-text>
      </claim-text>
    </claim>
  </claims>
</lexisnexis-patent-document>