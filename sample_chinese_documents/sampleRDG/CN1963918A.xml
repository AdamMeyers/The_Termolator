<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright ©2011 LexisNexis Univentio, The Netherlands. -->
<lexisnexis-patent-document schema-version="1.08" date-produced="20111005" file="CN1963918A.xml" produced-by="LexisNexis-Univentio" lang="eng" date-changed="20110506" time-changed="150250">
  <bibliographic-data lang="chi">
    <publication-reference publ-type="Application" publ-desc="Unexamined application for a patent for invention">
      <document-id>
        <country>CN</country>
        <doc-number>1963918</doc-number>
        <kind>A</kind>
        <date>20070516</date>
      </document-id>
    </publication-reference>
    <application-reference>
      <document-id>
        <country>CN</country>
        <doc-number>200510115300</doc-number>
        <date>20051111</date>
      </document-id>
    </application-reference>
    <language-of-filing>eng</language-of-filing>
    <language-of-publication>chi</language-of-publication>
    <priority-claims date-changed="20070815">
      <priority-claim sequence="1" kind="national">
        <country>CN</country>
        <doc-number>200510115300</doc-number>
        <date>20051111</date>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability date-changed="20091225">
      <gazette-reference>
        <date>20070516</date>
      </gazette-reference>
      <unexamined-printed-without-grant>
        <date>20070516</date>
      </unexamined-printed-without-grant>
    </dates-of-public-availability>
    <kind-of-official-gazette lang="eng">23-20</kind-of-official-gazette>
    <classification-ipc date-changed="20091227">
      <main-classification>
        <text>  G 10L  17/00   A</text>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>17</main-group>
        <subgroup>00</subgroup>
        <qualifying-character>A</qualifying-character>
      </main-classification>
    </classification-ipc>
    <classifications-ipcr date-changed="20091227">
      <classification-ipcr sequence="1">
        <text>G10L  17/00        20060101CFI20070516BHCN        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>C</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>17</main-group>
        <subgroup>00</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20070516</date>
        </action-date>
        <generating-office>
          <country>CN</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G10L  17/00        20060101AFI20070516BHCN        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>17</main-group>
        <subgroup>00</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20070516</date>
        </action-date>
        <generating-office>
          <country>CN</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
    </classifications-ipcr>
    <classifications-ecla date-changed="20091227">
      <classification-ecla sequence="1" classification-scheme="EC" country="EP">
        <text>G10L 17/00B6</text>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>17</main-group>
        <subgroup>00</subgroup>
        <additional-subgroups>
          <additional-subgroup sequence="1">B  </additional-subgroup>
          <additional-subgroup sequence="2">6  </additional-subgroup>
        </additional-subgroups>
      </classification-ecla>
      <classification-ecla sequence="1" classification-scheme="ICO" country="EP">
        <text>S10L101:10</text>
        <section>S</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>101</main-group>
        <subgroup>10</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <number-of-claims calculated="yes">32</number-of-claims>
    <invention-title id="title_chi" date-changed="20091229" lang="chi" format="original">说话人模板的压缩、合并装置和方法，以及说话人认证</invention-title>
    <invention-title id="title_eng" date-changed="20091229" lang="eng" format="original">Compress of speaker cyclostyle, combination apparatus and method and authentication of speaker</invention-title>
    <references-cited date-changed="20110711">
      <forward-citations name="fwdcit" date-changed="20110711" />
      <citation>
        <fwdcit num="1">
          <document-id>
            <country>CN</country>
            <doc-number>101465123</doc-number>
            <kind>B</kind>
            <date>20110706</date>
          </document-id>
          <application-date>
            <date>20071220</date>
          </application-date>
        </fwdcit>
      </citation>
    </references-cited>
    <parties date-changed="20091225">
      <applicants>
        <applicant sequence="1" app-type="applicant">
          <addressbook lang="chi">
            <orgname>株式会社东芝</orgname>
            <address>
              <address-1>日本东京都</address-1>
            </address>
          </addressbook>
          <addressbook lang="eng">
            <orgname>TOKYO SHIBAURA ELECTRIC CO.</orgname>
            <address>
              <country>JP</country>
            </address>
          </addressbook>
        </applicant>
        <applicant sequence="1" app-type="applicant" data-format="original">
          <addressbook lang="chi">
            <orgname>株式会社东芝</orgname>
            <address>
              <address-1>日本东京都</address-1>
            </address>
          </addressbook>
        </applicant>
        <applicant sequence="1" app-type="applicant" data-format="docdb">
          <addressbook lang="eng">
            <orgname>TOKYO SHIBAURA ELECTRIC CO</orgname>
            <address>
              <country>JP</country>
            </address>
          </addressbook>
        </applicant>
        <applicant sequence="1" app-type="applicant" data-format="docdba">
          <addressbook lang="eng">
            <orgname>TOKYO SHIBAURA ELECTRIC CO.</orgname>
            <address>
              <country>JP</country>
            </address>
          </addressbook>
        </applicant>
      </applicants>
      <inventors>
        <inventor sequence="1">
          <addressbook lang="chi">
            <name>栾剑</name>
          </addressbook>
          <addressbook lang="eng">
            <name>LUAN JIAN,HAO JIE</name>
            <address>
              <country>JP</country>
            </address>
          </addressbook>
        </inventor>
        <inventor sequence="2">
          <addressbook lang="chi">
            <name>郝杰</name>
          </addressbook>
        </inventor>
        <inventor sequence="1" data-format="original">
          <addressbook lang="chi">
            <name>栾剑</name>
          </addressbook>
        </inventor>
        <inventor sequence="1" data-format="docdb">
          <addressbook lang="eng">
            <name>JIE LUAN JIAN HAO</name>
            <address>
              <country>JP</country>
            </address>
          </addressbook>
        </inventor>
        <inventor sequence="1" data-format="docdba">
          <addressbook lang="eng">
            <name>LUAN JIAN,HAO JIE</name>
            <address>
              <country>JP</country>
            </address>
          </addressbook>
        </inventor>
        <inventor sequence="2" data-format="original">
          <addressbook lang="chi">
            <name>郝杰</name>
          </addressbook>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="attorney">
          <addressbook lang="chi">
            <name>北京市中咨律师事务所 (李峥)</name>
          </addressbook>
        </agent>
        <agent sequence="2" rep-type="attorney">
          <addressbook lang="chi">
            <name>北京市中咨律师事务所 (于静)</name>
          </addressbook>
        </agent>
        <agent sequence="1" rep-type="attorney" data-format="original">
          <addressbook lang="chi">
            <name>北京市中咨律师事务所 (李峥)</name>
          </addressbook>
        </agent>
        <agent sequence="2" rep-type="attorney" data-format="original">
          <addressbook lang="chi">
            <name>北京市中咨律师事务所 (于静)</name>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <patent-family date-changed="20070821">
      <main-family family-id="59943043">
        <family-member>
          <document-id>
            <country>CN</country>
            <doc-number>1963918</doc-number>
            <kind>A</kind>
            <date>20070516</date>
          </document-id>
          <application-date>
            <date>20051111</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>20070129944</doc-number>
            <kind>A1</kind>
            <date>20070607</date>
          </document-id>
          <application-date>
            <date>20061018</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>JP</country>
            <doc-number>2007133413</doc-number>
            <kind>A</kind>
            <date>20070531</date>
          </document-id>
          <application-date>
            <date>20061113</date>
          </application-date>
        </family-member>
      </main-family>
      <complete-family family-id="59892287">
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>20070129944</doc-number>
            <kind>A1</kind>
            <date>20070607</date>
          </document-id>
          <application-date>
            <date>20061018</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>JP</country>
            <doc-number>2007133413</doc-number>
            <kind>A</kind>
            <date>20070531</date>
          </document-id>
          <application-date>
            <date>20061113</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>CN</country>
            <doc-number>1963918</doc-number>
            <kind>A</kind>
            <date>20070516</date>
          </document-id>
          <application-date>
            <date>20051111</date>
          </application-date>
        </family-member>
      </complete-family>
    </patent-family>
  </bibliographic-data>
  <abstract id="abstr_chi" date-changed="20091227" lang="chi" format="original">
    <p num="1">本发明提供了说话人模板的压缩方法和装置、将多个说话人模板合并的方法和装置、说话人认证的注册方法和装置、说话人认证的验证方法和装置、以及说话人认证系统。该说话人模板包含多个特征向量。本发明的说话人模板的压缩方法包括：根据一个码本，为说话人模板中的每个上述特征向量指定一个码字，其中上述码本包含多个码字以及每个码字对应的特征向量；以及将上述说话人模板中相邻且被指定的码字相同的多个特征向量用一个特征向量代替。</p>
  </abstract>
  <abstract id="abstr_eng" date-changed="20091227" lang="eng" format="original">
    <p>The patent refers to the field of 'speech analysis or synthesis and speech recognition'. This invention supplies one speaker mode compression method and device, multiple person merging method and device, speaker identification register method and device, speaker identification test method and device and speaker identification system. The compressing method comprises the following steps: designing each code form each above character vector in speaker mode, wherein, the code comprises multiple codes and relative vectors; taking place of the above speaker mode adjacent codes and vectors by one characteristic vector.</p>
  </abstract>
  <legal-data date-changed="20110408">
    <legal-event sequence="1">
      <publication-date>
        <date>20070516</date>
      </publication-date>
      <event-code-1>C06</event-code-1>
      <effect>+</effect>
      <legal-description>PUBLICATION</legal-description>
      <status-identifier>N</status-identifier>
      <docdb-publication-number> CN     1963918A</docdb-publication-number>
    </legal-event>
    <legal-event sequence="2">
      <publication-date>
        <date>20070711</date>
      </publication-date>
      <event-code-1>C10</event-code-1>
      <legal-description>REQUEST OF EXAMINATION AS TO SUBSTANCE</legal-description>
      <status-identifier>N</status-identifier>
      <docdb-publication-number> CN     1963918A</docdb-publication-number>
    </legal-event>
    <legal-event sequence="3">
      <publication-date>
        <date>20110105</date>
      </publication-date>
      <event-code-1>C20</event-code-1>
      <effect>-</effect>
      <legal-description>PATENT RIGHT DEEMED TO BE ABANDONED</legal-description>
      <status-identifier>N</status-identifier>
      <docdb-publication-number> CN     1963918A</docdb-publication-number>
    </legal-event>
  </legal-data>
  <description id="descr_chi" lang="chi" format="original" date-changed="20091225">
    <technical-field>
      <p id="p-0001-zh" num="0001">技术领域 		 	 	 
                <br /></p>
      <p id="p-0002-zh" num="0002">本发明涉及信息处理技术，具体地涉及说话人模板(speaker template) 	    	 
                <br />的压缩、合并以及说话人认证(speaker authentification)的技术。 		 	 	 
                <br /></p>
    </technical-field>
    <background-art>
      <p id="p-0003-zh" num="0003">背景技术  		  	 
                <br /></p>
      <p id="p-0004-zh" num="0004">利用每个人说话时的发音特点可以识别出不同的说话人，从而可以进 		 	 	 
                <br />行说话人的认证。在K.Yu，J.Mason，J.Oglesby发表的文章“Speaker  		  	 
                <br />recognition using hidden Markov models，dynamic time warping and	 	 	 	 
                <br />vector quantisation”(Vision，Image and Signal Processing，IEE 	    	 
                <br />Proceedings，Vol.142，Oct.1995，pp.313-18)中介绍了常见地三种说话人 		 	 	 
                <br />识别引擎技术：HMM，DTW和VQ。  		  	 
                <br /></p>
      <p id="p-0005-zh" num="0005">通常，说话人认证的过程包括注册(enrollment)和验证(evaluation) 		 	 	 
                <br />两个阶段。在注册阶段，根据说话人(用户)本人朗读的包含密码的语音，  		  	 
                <br />生成该说话人的说话人模板；在验证阶段，根据说话人模板判断测试语音	 	 	 	 
                <br />是否为该说话人本人说出的相同密码的语音。因此，说话人模板的质量对 	    	 
                <br />于整个认证过程非常重要。 		 	 	 
                <br /></p>
      <p id="p-0006-zh" num="0006">已知为了提高说话人模板的质量，可以采用多个训练语音来构建一个 	    	 
                <br />说话人模板。首先选定一个训练语音作为初始模板，然后用DTW的方法 		 	 	 
                <br />将第二个训练语音与之时间对齐，并用两段语音中相对应的特征向量的平  		  	 
                <br />均来生成一个新的模板，然后再将第三个训练语音与新模板时间对齐，如	 	 	 	 
                <br />此循环直到所有的训练语音都结合到一个独立的模板中，即所谓的模板合 	    	 
                <br />并。详细内容可以参考W.H.Abdulla、D.Chow和G.Sin发表的文章 		 	 	 
                <br />“Cross-words reference template for DTW-based speech recognition  		  	 
                <br />systems”(IEEE TENCON 2003，pp.1576-1579)。 	    	 
                <br /></p>
      <p id="p-0007-zh" num="0007">另一方面，如果需要进行模板压缩以节约存储空间，通常会对模板中	 	 	 	 
                <br />的特征向量序列进行简单的降采样。详细内容可以参考X.Wen和R.Liu 	    	 
                <br />发表的文章“Enhancing the stability of speaker verification with 		 	 	 
                <br />compressed templates”(ISCSLP 2002，pp.111-114)。但是，采用这种  		  	 
                <br />方式压缩模板时会对模板的质量产生影响，并最终导致验证错误的增加。	 	 	 	 
                <br /></p>
      <p id="p-0008-zh" num="0008">进而，当仅有少量的训练语音时，往往所有的模板共用一个先验阈值。  		  	 
                <br />这样，由于阈值的针对性差，也会导致验证错误率提高的问题。	 	 	 	 
                <br /></p>
    </background-art>
    <disclosure>
      <p id="p-0009-zh" num="0009">发明内容 	    	 
                <br /></p>
      <p id="p-0010-zh" num="0010">为了解决上述现有技术中存在的问题，本发明提供了说话人模板的压	 	 	 	 
                <br />缩方法和装置、将多个说话人模板合并的方法和装置、说话人认证的注册 	    	 
                <br />方法和装置、说话人认证的验证方法和装置、以及说话人认证系统。 		 	 	 
                <br /></p>
      <p id="p-0011-zh" num="0011">根据本发明的一个方面，提供了一种说话人模板的压缩方法，其中， 	    	 
                <br />该说话人模板包含多个特征向量，该方法包括：根据一个码本，为说话人 		 	 	 
                <br />模板中的每个上述特征向量指定一个码字，其中上述码本包含多个码字以  		  	 
                <br />及每个码字对应的特征向量；以及将上述说话人模板中相邻且被指定的码	 	 	 	 
                <br />字相同的多个特征向量用一个特征向量代替。 	    	 
                <br /></p>
      <p id="p-0012-zh" num="0012">进而，还可以将压缩后的上述说话人模板中的特征向量对应的码字序	 	 	 	 
                <br />列保存为背景模板。 	    	 
                <br /></p>
      <p id="p-0013-zh" num="0013">根据本发明的另一个方面，提供了一种将多个说话人模板合并的方法，	 	 	 	 
                <br />包括：利用前面所述的说话人模板的压缩方法，分别对上述多个说话人模 	    	 
                <br />板进行压缩；以及对上述压缩后的多个说话人模板进行DTW合并。 		 	 	 
                <br /></p>
      <p id="p-0014-zh" num="0014">根据本发明的另一个方面，提供了一种将多个说话人模板合并的方法， 	    	 
                <br />包括：对上述多个说话人模板进行DTW合并，形成一个单独模板；以及 		 	 	 
                <br />利用前面所述的说话人模板的压缩方法，对上述合并后的说话人模板进行  		  	 
                <br />压缩。	 	 	 	 
                <br /></p>
      <p id="p-0015-zh" num="0015">根据本发明的另一个方面，提供了一种将多个说话人模板合并的方法，  		  	 
                <br />包括：利用前面所述的说话人模板的压缩方法，对上述多个说话人模板中 	    	 
                <br />的至少一个说话人模板进行压缩；以及将上述压缩后的至少一个说话人模 		 	 	 
                <br />板与其它的说话人模板DTW合并。  		  	 
                <br /></p>
      <p id="p-0016-zh" num="0016">根据本发明的另一个方面，提供了一种说话人认证的注册方法，包括： 		 	 	 
                <br />根据说话人输入的多个语音生成多个说话人模板；以及利用前面所述的将  		  	 
                <br />多个说话人模板合并的方法，将上述生成的多个说话人模板合并。	 	 	 	 
                <br /></p>
      <p id="p-0017-zh" num="0017">根据本发明的另一个方面，提供了一种说话人认证的验证方法，包括：  		  	 
                <br />输入语音；以及根据说话人模板，判断该输入的语音是否为说话人本人说	 	 	 	 
                <br />出的注册密码语音，其中，上述说话人模板是利用前面所述的说话人模板 	    	 
                <br />的压缩方法生成的。 		 	 	 
                <br /></p>
      <p id="p-0018-zh" num="0018">根据本发明的另一个方面，提供了一种说话人认证的验证方法，包括： 	    	 
                <br />输入语音；以及根据说话人模板和背景模板，判断该输入的语音是否为说 		 	 	 
                <br />话人本人说出的注册密码语音，其中，上述说话人模板和背景模板是利用  		  	 
                <br />前面所述的说话人模板的压缩方法生成的。	 	 	 	 
                <br /></p>
      <p id="p-0019-zh" num="0019">根据本发明的另一个方面，提供了一种说话人模板的压缩装置，其中，  		  	 
                <br />该说话人模板包含多个特征向量，包括：码字指定单元(code designating	 	 	 	 
                <br />unit)，其根据一个码本为说话人模板中的每个上述特征向量指定一个码 	    	 
                <br />字，其中上述码本包含多个码字以及每个码字对应的特征向量；以及向量 		 	 	 
                <br />合并单元(vector merging unit)，其将上述说话人模板中相邻且被指定的  		  	 
                <br />码字相同的多个特征向量用一个特征向量代替。	 	 	 	 
                <br /></p>
      <p id="p-0020-zh" num="0020">根据本发明的另一个方面，提供了一种将多个说话人模板合并的装置，  		  	 
                <br />包括：前面所述的说话人模板的压缩装置；以及DTW合并装置(DTW	 	 	 	 
                <br />merging unit)，用于对两个说话人模板进行DTW合并。 	    	 
                <br /></p>
      <p id="p-0021-zh" num="0021">根据本发明的另一个方面，提供了一种说话人认证的注册装置，包括：	 	 	 	 
                <br />模板生成装置(template generator)，用于根据说话人输入的语音生成说 	    	 
                <br />话人模板；以及前面所述的将多个说话人模板合并的装置，将由上述模板 		 	 	 
                <br />生成装置生成的多个说话人模板合并。  		  	 
                <br /></p>
      <p id="p-0022-zh" num="0022">根据本发明的另一个方面，提供了一种说话人认证的验证装置，包括： 		 	 	 
                <br />语音输入单元(utterance input unit)，用于输入语音；声学特征提取单元	 	 	 	 
                <br />(acoustic feature extractor)，用于从上述输入的语音提取声学特征；以及 	    	 
                <br />匹配得分计算单元(matching score calculator)，用于计算上述提取出的 		 	 	 
                <br />声学特征与相应的说话人模板的DTW匹配得分，其中，上述说话人模板  		  	 
                <br />是利用前面所述的说话人模板的压缩方法生成的；其中，通过比较上述计	 	 	 	 
                <br />算出的DTW匹配得分和预先设定的分辨阈值，判断输入的语音是否为说 	    	 
                <br />话人本人说出的注册密码语音。 		 	 	 
                <br /></p>
      <p id="p-0023-zh" num="0023">根据本发明的另一个方面，提供了一种说话人认证的验证装置，包括： 	    	 
                <br />语音输入单元(utterance input unit)，用于输入语音；声学特征提取单元 		 	 	 
                <br />(acoustic feature extractor)，用于从上述输入的语音提取声学特征；匹配  		  	 
                <br />得分计算单元(matching score calculator)，计算上述提取出的声学特征	 	 	 	 
                <br />与说话人模板的DTW匹配得分，以及计算上述提取出的声学特征与背景 	    	 
                <br />模板的DTW匹配得分，其中上述说话人模板和背景模板是利用前面所述 		 	 	 
                <br />的说话人模板的压缩方法生成的；以及归一化单元(normalizing unit)，  		  	 
                <br />其利用上述提取出的声学特征与上述背景模板的DTW匹配得分，对上述	 	 	 	 
                <br />提取出的声学特征与上述说话人模板的DTW匹配得分进行归一化；其中， 	    	 
                <br />比较上述归一化后的DTW匹配得分和一个阈值，判断输入的语音是否为 		 	 	 
                <br />说话人本人说出的注册密码语音。  		  	 
                <br /></p>
      <p id="p-0024-zh" num="0024">根据本发明的另一个方面，提供了一种说话人认证的验证装置，包括： 		 	 	 
                <br />语音输入单元(utterance input unit)，用于输入语音；声学特征提取单元  		  	 
                <br />(acoustic feature extractor)，用于从上述输入的语音提取声学特征；匹配	 	 	 	 
                <br />得分计算单元(matching score calculator)，用于计算上述提取出的声学 	    	 
                <br />特征与说话人模板的DTW匹配得分，以及计算上述说话人模板与背景模 		 	 	 
                <br />板的DTW匹配得分；其中上述说话人模板和背景模板是利用前面所述的  		  	 
                <br />说话人模板的压缩方法生成的；以及归一化单元(normalizing unit)，其	 	 	 	 
                <br />利用上述说话人模板与上述背景模板的DTW匹配得分，对上述提取出的 	    	 
                <br />声学特征与上述说话人模板的DTW匹配得分进行归一化；其中，比较上 		 	 	 
                <br />述归一化后的DTW匹配得分和一个阈值，判断输入的语音是否为说话人  		  	 
                <br />本人说出的注册密码语音。 	    	 
                <br /></p>
      <p id="p-0025-zh" num="0025">根据本发明的另一个方面，提供了一种说话人认证系统，包括：前面	 	 	 	 
                <br />所述的说话人认证的注册装置；以及前面所述的说话人认证的验证装置。 	    	 
                <br /></p>
    </disclosure>
    <description-of-drawings>
      <p id="p-0026-zh" num="0026">附图说明 		 	 	 
                <br /></p>
      <p id="p-0027-zh" num="0027">相信通过以下结合附图对本发明具体实施方式的说明，能够使人们更 	    	 
                <br />好地了解本发明上述的特点、优点和目的。 		 	 	 
                <br /></p>
      <p id="p-0028-zh" num="0028">图1是根据本发明一个实施例的说话人模板的压缩方法的流程图； 	    	 
                <br /></p>
      <p id="p-0029-zh" num="0029">图2是根据本发明另一个实施例的说话人模板的压缩方法的流程图；	 	 	 	 
                <br /></p>
      <p id="p-0030-zh" num="0030">图3A～3C是根据本发明的三个实施例的将多个说话人模板合并的方  		  	 
                <br />法的流程图；	 	 	 	 
                <br /></p>
      <p id="p-0031-zh" num="0031">图4是根据本发明的一个实施例的说话人认证的验证方法的流程图；  		  	 
                <br /></p>
      <p id="p-0032-zh" num="0032">图5是根据本发明的另一个实施例的说话人认证的验证方法的流程 		 	 	 
                <br />图；  		  	 
                <br /></p>
      <p id="p-0033-zh" num="0033">图6是根据本发明的再另一个实施例的说话人认证的验证方法的流程 		 	 	 
                <br />图；  		  	 
                <br /></p>
      <p id="p-0034-zh" num="0034">图7是根据本发明一个实施例的说话人模板的压缩装置的方框图； 		 	 	 
                <br /></p>
      <p id="p-0035-zh" num="0035">图8是根据本发明一个实施例的将多个说话人模板合并的装置的方框 	    	 
                <br />图； 		 	 	 
                <br /></p>
      <p id="p-0036-zh" num="0036">图9是根据本发明一个实施例的说话人认证的注册装置的方框图； 	    	 
                <br /></p>
      <p id="p-0037-zh" num="0037">图10是根据本发明一个实施例的说话人认证的验证装置的方框图；	 	 	 	 
                <br /></p>
      <p id="p-0038-zh" num="0038">图11是根据本发明另一个实施例的说话人认证的验证装置的方框图；  		  	 
                <br />以及	 	 	 	 
                <br /></p>
      <p id="p-0039-zh" num="0039">图12是根据本发明一个实施例的说话人认证系统的方框图。  		  	 
                <br /></p>
    </description-of-drawings>
    <mode-for-invention>
      <p id="p-0040-zh" num="0040">具体实施方式	 	 	 	 
                <br /></p>
      <p id="p-0041-zh" num="0041">下面就结合附图对本发明的各个优选实施例进行详细的说明。  		  	 
                <br /></p>
      <p id="p-0042-zh" num="0042">图1是根据本发明一个实施例的说话人模板的压缩方法的流程图。如 		 	 	 
                <br />图1所示，首先在步骤101，在码本中为需要压缩的说话人模板中的每个	 	 	 	 
                <br />特征向量查找与之最接近的特征向量。在本实施例中使用的码本是在整个 	    	 
                <br />应用的声学空间中训练出的码本，例如，对于中文语言应用环境来说，该 		 	 	 
                <br />码本需要能够涵盖中文语音的声学空间；对于英文语言应用环境来说，该  		  	 
                <br />码本则需要能够涵盖英文语音的声学空间。当然，对于一些特殊用途的应	 	 	 	 
                <br />用环境，也可以相应的改变码本所涵盖的声学空间。 	    	 
                <br /></p>
      <p id="p-0043-zh" num="0043">本实施例的码本包含多个码字以及每个码字对应的特征向量。码字的	 	 	 	 
                <br />数量取决于声学空间的大小、希望的压缩比例和希望的压缩质量。声学空 	    	 
                <br />间越大需要的码字的数量越大。在同样的声学空间的条件下，码字的数量 		 	 	 
                <br />越小，压缩比例越高；码字的数量越大，压缩的模板质量越高。根据本发  		  	 
                <br />明的一个优选实施例，在普通中文语音的声学空间下，码字的数量优选为	 	 	 	 
                <br />256至512。当然，根据不同需要，可以适当调节码本的码字数量和涵盖的 	    	 
                <br />声学空间。 		 	 	 
                <br /></p>
      <p id="p-0044-zh" num="0044">在本步骤中，可以通过计算说话人模板中的特征向量和码本中每个特 	    	 
                <br />征向量的距离(例如，欧氏距离)，来找出最接近的特征向量。 		 	 	 
                <br /></p>
      <p id="p-0045-zh" num="0045">接着，在步骤105，将码本中与该最接近的特征向量对应的码字指定 	    	 
                <br />给说话人模板中对应的特征向量。 		 	 	 
                <br /></p>
      <p id="p-0046-zh" num="0046">然后，将说话人模板中相邻且被指定的码字相同的多个特征向量用一 	    	 
                <br />个特征向量代替。具体地，根据本实施例，首先，计算上述相邻且码字相 		 	 	 
                <br />同的一组特征向量的平均向量，然后，用计算的平均向量代替上述相邻且  		  	 
                <br />码字相同的一组特征向量。	 	 	 	 
                <br /></p>
      <p id="p-0047-zh" num="0047">如果在说话人模板中存在有多组这样的相邻且码字相同的多个特征向  		  	 
                <br />量，则可以按照上述方式逐一地进行替换。这样，逐一地将多个特征向量	 	 	 	 
                <br />替换为一个特征向量，说话人模板中的特征向量的数量就减少了，模板也 	    	 
                <br />就被压缩了。 		 	 	 
                <br /></p>
      <p id="p-0048-zh" num="0048">通过以上描述可知，如果采用本实施例的说话人模板的压缩方法，可 	    	 
                <br />以对说话人模板进行压缩，在本优选实施例的情况下可以将说话人模板压 		 	 	 
                <br />缩到原长度的约三分之一，大大节省了系统所需的存储空间。并且，由于  		  	 
                <br />不是采用单纯的降采样，而是将接近的连续特征向量(相邻且码字相同的 	    	 
                <br />多个特征向量)用它们的平均代替，系统的性能还得到了提高。 		 	 	 
                <br /></p>
      <p id="p-0049-zh" num="0049">在此需要指出，在本优选实施例中虽然采用MFCC(Mel Frequency 	    	 
                <br />Cepstrum Coefficient，Mel频率倒谱系数)的方式来表示语音的声学特征。 		 	 	 
                <br />但是，本发明对此并没有特别的限制，也可以采用已知的和未来的其它方  		  	 
                <br />式来表示语音的声学特征，例如，LPCC(Linear Predictive Cepstrum	 	 	 	 
                <br />Coefficient，线性预测倒谱系数)或者其它基于能量、基音频率或小波分 	    	 
                <br />析等得到的各种系数等，只要是能够表现说话人的个人语音特点即可。 		 	 	 
                <br /></p>
      <p id="p-0050-zh" num="0050">另外，根据本实施例的一个变形例，不是将接近的连续特征向量(相 	    	 
                <br />邻且码字相同的多个特征向量)用它们的平均代替，而是，从相邻且码字 		 	 	 
                <br />相同的一组特征向量中随机选择一个代表向量，用这个代表向量代替这些  		  	 
                <br />相邻且码字相同的多个特征向量。	 	 	 	 
                <br /></p>
      <p id="p-0051-zh" num="0051">可替代地，也可以从相邻且码字相同的多个特征向量中选择与码本中  		  	 
                <br />该码字对应的特征向量最接近的特征向量作为代表向量，用这个代表向量	 	 	 	 
                <br />代替这些相邻且码字相同的多个特征向量。 	    	 
                <br /></p>
      <p id="p-0052-zh" num="0052">另外，可替代地，也可以用码本中与该码字对应的特征向量代替这些	 	 	 	 
                <br />相邻且码字相同的多个特征向量。 	    	 
                <br /></p>
      <p id="p-0053-zh" num="0053">另外，可替代地，也可以计算相邻且被指定的码字相同的多个特征向	 	 	 	 
                <br />量的每一个和上述码本中与该码字对应的特征向量的距离；然后，从这些 	    	 
                <br />相邻且码字相同的多个特征向量中除去一个或多个距离最远的特征向量， 		 	 	 
                <br />计算剩余的特征向量的平均向量；最后用计算出的平均向量代替上述相邻  		  	 
                <br />且码字相同的多个特征向量。	 	 	 	 
                <br /></p>
      <p id="p-0054-zh" num="0054">图2是根据本发明另一个实施例的说话人模板的压缩方法的流程图。  		  	 
                <br />下面就结合该图，对本实施例进行描述。对于那些与前面实施例相同的部	 	 	 	 
                <br />分，适当省略其说明。 	    	 
                <br /></p>
      <p id="p-0055-zh" num="0055">如图2所示，本实施例的说话人模板的压缩方法的步骤101至110与	 	 	 	 
                <br />图1所示的实施例相同，在此不再重复。 	    	 
                <br /></p>
      <p id="p-0056-zh" num="0056">在用一个特征向量代替模板中相邻且码字相同的多个特征向量(步骤	 	 	 	 
                <br />110)之后，在步骤215，将压缩后的说话人模板中的特征向量对应的码字 		 	 	 
                <br />序列保存为背景模板。具体地，经过前面步骤101至110将说话人模板压  		  	 
                <br />缩之后，模板中包含有相对于原始模板数量减少了的特征向量，这些特征	 	 	 	 
                <br />向量构成了一个特征向量序列，并且，每个特征向量都被指定了一个码字， 	    	 
                <br />于是，这个特征向量序列也就对应了一个码字序列。在本步骤中，就是将 		 	 	 
                <br />这个码字序列保存作为背景模板。  		  	 
                <br /></p>
      <p id="p-0057-zh" num="0057">这样，本实施例的说话人模板的压缩方法不仅可以生成一个压缩了的 		 	 	 
                <br />说话人模板，而且还生成了一个背景模板。这个背景模板将被后面描述的  		  	 
                <br />说话人认证的验证方法和装置用来对匹配得分进行归一化，从而提高验证	 	 	 	 
                <br />的准确性。 	    	 
                <br /></p>
      <p id="p-0058-zh" num="0058">在同一发明构思下，图3A～3C是根据本发明的三个实施例的将多个	 	 	 	 
                <br />说话人模板合并的方法的流程图。下面就结合图3，对这些实施例进行描 	    	 
                <br />述。对于那些与前面实施例相同的部分，适当省略其说明。 		 	 	 
                <br /></p>
      <p id="p-0059-zh" num="0059">如图3A所示，该实施例的将多个说话人模板合并的方法，首先在步 	    	 
                <br />骤3101，利用前面所述实施例的说话人模板的压缩方法，分别对要合并的 		 	 	 
                <br />多个说话人模板进行压缩。  		  	 
                <br /></p>
      <p id="p-0060-zh" num="0060">然后，在步骤3105，逐一地对压缩后的多个说话人模板进行DTW合 		 	 	 
                <br />并。具体地，可以采用现有的模板合并方法，如前面引用的W.H.Abdulla、  		  	 
                <br />D.Chow和G.Sin发表的文章“Cross-words reference template for	 	 	 	 
                <br />DTW-based speech recognition systems”(IEEE TENCON 2003， 	    	 
                <br />pp.1576-1579)中所描述的那样，首先选定一个模板作为初始模板，然后 		 	 	 
                <br />用DTW的方法将第二个模板与之时间对齐，并用两个模板中相对应的特  		  	 
                <br />征向量的平均来生成一个新的模板，然后再将第三个模板与新模板时间对	 	 	 	 
                <br />齐，如此循环直到所有的训练语音都结合到一个单独的模板中。在本申请 	    	 
                <br />中，将这种模板合并方法称为DTW合并。 		 	 	 
                <br /></p>
      <p id="p-0061-zh" num="0061">通过上面描述可知，如果采用本实施例的将多个说话人模板合并的方 	    	 
                <br />法，由于每一个说话人模板在DTW合并之前已经用前面实施例的模板压 		 	 	 
                <br />缩方法进行了压缩，因此，合并后的说话人模板的长度大大减小，从而可  		  	 
                <br />以节省存储空间。 	    	 
                <br /></p>
      <p id="p-0062-zh" num="0062">如图3B所示，该实施例的将多个说话人模板合并的方法，首先在步	 	 	 	 
                <br />骤3201，逐一地对多个说话人模板进行DTW合并，形成一个单独的模板。 	    	 
                <br /></p>
      <p id="p-0063-zh" num="0063">然后，在步骤3205，利用前面所述实施例的说话人模板的压缩方法，	 	 	 	 
                <br />对DTW合并后的单独说话人模板进行压缩。 	    	 
                <br /></p>
      <p id="p-0064-zh" num="0064">如果采用本实施例的将多个说话人模板合并的方法，由于在DTW合	 	 	 	 
                <br />并后，又用前面实施例的模板压缩方法对说话人模板进行了压缩，因此， 	    	 
                <br />合并后的说话人模板的长度大大减小，从而可以节省存储空间。 		 	 	 
                <br /></p>
      <p id="p-0065-zh" num="0065">如图3C所示，该实施例的将多个说话人模板合并的方法，首先在步 	    	 
                <br />骤3301，利用前面所述实施例的说话人模板的压缩方法，对要合并的多个 		 	 	 
                <br />说话人模板中的一个模板进行压缩。  		  	 
                <br /></p>
      <p id="p-0066-zh" num="0066">然后，在步骤3305，逐一地将压缩后的说话人模板与剩下的模板进行 		 	 	 
                <br />DTW合并。在此需要指出，在步骤3305的DTW合并过程中，需要以压  		  	 
                <br />缩后的说话人模板为基准模板。因为，DTW合并后的模板中的特征向量	 	 	 	 
                <br />的数量是以基准模板为准的，也就是说，在两个模板DTW对齐之后，以 	    	 
                <br />基准模板的每个特征向量为单位进行平均和合并。因此，如果以未压缩的 		 	 	 
                <br />模板为基准模板进行DTW合并，那么最后就取得不了减少特征向量的数  		  	 
                <br />量的效果。	 	 	 	 
                <br /></p>
      <p id="p-0067-zh" num="0067">通过上面描述可知，如果采用本实施例的将多个说话人模板合并的方  		  	 
                <br />法，同样可以减小说话人模板的长度，从而可以节省存储空间。	 	 	 	 
                <br /></p>
      <p id="p-0068-zh" num="0068">另外，在步骤3301中，也可以利用上书压缩方法，将要合并的多个模  		  	 
                <br />板中的一个以上的模板压缩。	 	 	 	 
                <br /></p>
      <p id="p-0069-zh" num="0069">在同一发明构思下，根据本发明的一个实施例，还提供了一种说话人  		  	 
                <br />认证的注册方法。本实施例的说话人认证的注册方法，首先，根据说话人	 	 	 	 
                <br />输入的多个语音生成多个说话人模板。具体地，可以采用以往的生成模板 	    	 
                <br />方式，例如，采样提取语音中的声学特征，根据提取出的声学特征形成说 		 	 	 
                <br />话人模板。关于声学特征和模板内容，前面已经进行了说明，在此不再重  		  	 
                <br />复。	 	 	 	 
                <br /></p>
      <p id="p-0070-zh" num="0070">接着，利用前面所述实施例的将多个说话人模板合并的方法，将生成	 	 	 	 
                <br />的多个说话人模板合并。 	    	 
                <br /></p>
      <p id="p-0071-zh" num="0071">这样，如果采用本实施例的说话人认证的注册方法，与以往的方法相	 	 	 	 
                <br />比，可以减小生成的说话人模板的长度，从而可以节省存储空间。并且， 	    	 
                <br />由于不是采用单纯的降采样的方式，所以不会过多地影响说话人模板的质 		 	 	 
                <br />量。  		  	 
                <br /></p>
      <p id="p-0072-zh" num="0072">在同一发明构思下，图4是根据本发明的一个实施例的说话人认证的 		 	 	 
                <br />验证方法的流程图。下面就结合该图，对本实施例进行描述。对于那些与  		  	 
                <br />前面实施例相同的部分，适当省略其说明。	 	 	 	 
                <br /></p>
      <p id="p-0073-zh" num="0073">如图4所示，首先在步骤401，输入测试语音。接着，在步骤405，从  		  	 
                <br />上述输入的测试语音提取声学特征。与前面描述的实施例相同，本发明对	 	 	 	 
                <br />于声学特征并没有特别的限制，可以采用例如，MFCC、LPCC或者其它 	    	 
                <br />基于能量、基音频率或小波分析等得到的各种系数等，只要是能够表现说 		 	 	 
                <br />话人的个人语音特点即可；但是，应当与用户注册时生成的说话人模板中  		  	 
                <br />采用的方式相对应。	 	 	 	 
                <br /></p>
      <p id="p-0074-zh" num="0074">接着，在步骤410，计算提取出的声学特征与说话人模板中包含的声  		  	 
                <br />学特征的DTW匹配距离。在此，本实施例中的说话人模板是利用前面实	 	 	 	 
                <br />施例的说话人模板的压缩方法生成的说话人模板。 	    	 
                <br /></p>
      <p id="p-0075-zh" num="0075">然后，在步骤415，判断上述DTW匹配距离是否小于预先设定的分	 	 	 	 
                <br />辨阈值。如果是，则在步骤420认定是同一说话人说出的相同的密码，验 	    	 
                <br />证成功；如果否，则在步骤425认定验证失败。 		 	 	 
                <br /></p>
      <p id="p-0076-zh" num="0076">通过以上描述可知，如果采用本实施例的说话人认证的验证方法，可 	    	 
                <br />以利用前面实施例的说话人模板的压缩方法生成的说话人模板，对用户进 		 	 	 
                <br />行语音验证。由于说话人模板的数据量大大减小，因此，验证时可以大大  		  	 
                <br />减少运算量和存储空间，可以适用于处理能力和存储能力有限的终端设备。	 	 	 	 
                <br /></p>
      <p id="p-0077-zh" num="0077">图5是根据本发明的另一个实施例的说话人认证的验证方法的流程  		  	 
                <br />图。下面就结合该图，对本实施例进行描述。对于那些与前面实施例相同	 	 	 	 
                <br />的部分，适当省略其说明。 	    	 
                <br /></p>
      <p id="p-0078-zh" num="0078">本实施例与图4所示的实施例的区别在于，本实施例不仅使用了由前 	    	 
                <br />面实施例的说话人模板的压缩方法生成的说话人模板，而且使用了由前面 		 	 	 
                <br />实施例的说话人模板的压缩方法生成的背景模板来对判决进行归一化。  		  	 
                <br /></p>
      <p id="p-0079-zh" num="0079">如图5所示，在步骤401至410，本实施例与前面图4所示的实施例 		 	 	 
                <br />基本相同。接着，在步骤515，计算从测试语音中提取出的声学特征与背  		  	 
                <br />景模板的DTW匹配得分。具体地，如前面实施例所述，背景模板包含与	 	 	 	 
                <br />压缩后的说话人模板中的特征向量对应的码字序列。在本步骤中，根据码 	    	 
                <br />本中与上述码字序列中每个码字对应的特征向量，将背景模板中的码字序 		 	 	 
                <br />列转换为特征向量序列；然后，计算由背景模板转换的特征向量序列与从  		  	 
                <br />测试语音中提取出的声学特征的DTW匹配得分。	 	 	 	 
                <br /></p>
      <p id="p-0080-zh" num="0080">接着，在步骤520，利用测试语音的声学特征与上述背景模板的DTW  		  	 
                <br />匹配得分，对测试语音的声学特征与说话人模板的DTW匹配得分进行归	 	 	 	 
                <br />一化。即，测试语音的声学特征与说话人模板的DTW匹配得分减去测试 	    	 
                <br />语音的声学特征与上述背景模板的DTW匹配得分。 		 	 	 
                <br /></p>
      <p id="p-0081-zh" num="0081">接着，在步骤525，比较上述归一化后的DTW匹配得分和一个阈值， 	    	 
                <br />来判断测试语音是否为说话人本人说出的注册密码语音。 		 	 	 
                <br /></p>
      <p id="p-0082-zh" num="0082">如果归一化后的DTW匹配得分小于阈值，则在步骤530，认定是同 	    	 
                <br />一说话人说出的相同的密码，验证成功；如果否，则在步骤535认定验证 		 	 	 
                <br />失败。  		  	 
                <br /></p>
      <p id="p-0083-zh" num="0083">通过以上描述可知，如果采用本实施例的说话人认证的验证方法，可 		 	 	 
                <br />以利用前面实施例的说话人模板的压缩方法生成的说话人模板，对用户进  		  	 
                <br />行语音验证。由于说话人模板的数据量大大减小，因此，验证时可以大大	 	 	 	 
                <br />减少运算量和存储空间，可以适用于处理能力和存储能力有限的终端设备。 	    	 
                <br />进而，本实施例也为基于模板匹配的说话人验证系统提供了匹配得分的归 		 	 	 
                <br />一化方法。这样相当于为每一个模板设置了不同的最优阈值，使得系统性  		  	 
                <br />能大大提高。也就是说，即使采用统一的阈值，也可以根据不同的说话人	 	 	 	 
                <br />模板和背景模板进行适当的判断。 	    	 
                <br /></p>
      <p id="p-0084-zh" num="0084">图6是根据本发明的另一个实施例的说话人认证的验证方法的流程	 	 	 	 
                <br />图。下面就结合该图，对本实施例进行描述。对于那些与前面实施例相同 		 	 	 
                <br />的部分，适当省略其说明。  		  	 
                <br /></p>
      <p id="p-0085-zh" num="0085">本实施例与图5所示的实施例类似，不仅使用了利用前面实施例的说 		 	 	 
                <br />话人模板的压缩方法生成的说话人模板，而且使用了前面实施例的说话人  		  	 
                <br />模板的压缩方法生成的背景模板来对判决进行归一化。	 	 	 	 
                <br /></p>
      <p id="p-0086-zh" num="0086">如图6所示，在步骤401至410，本实施例与前面图4和图5所示的  		  	 
                <br />实施例基本相同。接着，在步骤615，计算背景模板与说话人模板的DTW	 	 	 	 
                <br />匹配得分。具体地，如前面实施例所述，背景模板包含与压缩后的说话人 	    	 
                <br />模板中的特征向量对应的码字序列。在本步骤中，根据码本中与上述码字 		 	 	 
                <br />序列中每个码字对应的特征向量，将背景模板中的码字序列转换为特征向  		  	 
                <br />量序列；然后，计算由背景模板转换的特征向量序列与说话人模板中的声	 	 	 	 
                <br />学特征的DTW匹配得分。 	    	 
                <br /></p>
      <p id="p-0087-zh" num="0087">接着，在步骤620，利用背景模板与说话人模板的DTW匹配得分，	 	 	 	 
                <br />对测试语音的声学特征与说话人模板的DTW匹配得分进行归一化。即， 	    	 
                <br />测试语音的声学特征与说话人模板的DTW匹配得分减去背景模板与说话 		 	 	 
                <br />人模板的DTW匹配得分。  		  	 
                <br /></p>
      <p id="p-0088-zh" num="0088">接着，在步骤625，比较上述归一化后的DTW匹配得分和一个阈值， 		 	 	 
                <br />来判断测试语音是否为说话人本人说出的注册密码语音。  		  	 
                <br /></p>
      <p id="p-0089-zh" num="0089">如果归一化后的DTW匹配得分小于阈值，则在步骤630，认定是同 		 	 	 
                <br />一说话人说出的相同的密码，验证成功；如果否，则在步骤635认定验证  		  	 
                <br />失败。	 	 	 	 
                <br /></p>
      <p id="p-0090-zh" num="0090">通过以上描述可知，如果采用本实施例的说话人认证的验证方法，可  		  	 
                <br />以利用前面实施例的说话人模板的压缩方法生成的说话人模板，对用户进	 	 	 	 
                <br />行语音验证。由于说话人模板的数据量大大减小，因此，验证时可以大大 	    	 
                <br />减少运算量和存储空间，可以适用于处理能力和存储能力有限的终端设备。 		 	 	 
                <br />进而，本实施例也为基于模板匹配的说话人验证系统提供了匹配得分的归  		  	 
                <br />一化方法。这样相当于为每一个模板设置了不同的最优阈值，使得系统性	 	 	 	 
                <br />能大大提高。也就是说，即使采用统一的阈值，也可以根据不同的说话人 	    	 
                <br />模板和背景模板进行适当的判断。  		  	 
                <br /></p>
      <p id="p-0091-zh" num="0091">在同一发明构思下，图7是根据本发明一个实施例的说话人模板的压 		 	 	 
                <br />缩装置的方框图。下面就结合该图，对本实施例进行描述。对于那些与前  		  	 
                <br />面实施例相同的部分，适当省略其说明。	 	 	 	 
                <br /></p>
      <p id="p-0092-zh" num="0092">如图7所示，本实施例的说话人模板的压缩装置700包括：码字指定  		  	 
                <br />单元(code designating unit)701，其根据码本为说话人模板中的每个特征	 	 	 	 
                <br />向量指定一个码字，关于码本和说话人模板的内容，前面已经进行了描述 	    	 
                <br />在此不再重复；向量合并单元(vector merging unit)705，其将说话人模 		 	 	 
                <br />板中相邻且被指定的码字相同的多个特征向量用一个特征向量代替。  		  	 
                <br /></p>
      <p id="p-0093-zh" num="0093">进而，说话人模板的压缩装置700还包括：向量距离计算单元(vector 		 	 	 
                <br />distance calculator)703，用于计算两个向量之间的距离；和码字查找单元  		  	 
                <br />(code search unit)704，其利用向量距离计算单元703，在码本中查找与	 	 	 	 
                <br />一个给定的特征向量最接近的特征向量及其对应的码字。这样，码字指定 	    	 
                <br />单元701可以利用码字查找单元704，为说话人模板中的每个特征向量在 		 	 	 
                <br />码本中找到一个最接近的特征向量，并将其对应的码字指定给模板中的该  		  	 
                <br />特征向量。	 	 	 	 
                <br /></p>
      <p id="p-0094-zh" num="0094">如图7所示，说话人模板的压缩装置700还包括：平均向量计算单元  		  	 
                <br />(average vector calculator)706，用于计算多个特征向量的平均向量。这	 	 	 	 
                <br />样，向量合并单元705就可以用平均向量计算单元706计算相邻且码字相 	    	 
                <br />同的多个特征向量的平均向量，来代替上述相邻且码字相同的多个特征向 		 	 	 
                <br />量。  		  	 
                <br /></p>
      <p id="p-0095-zh" num="0095">另外，根据本实施例的一个变形例，上述向量合并单元705也可以用 		 	 	 
                <br />平均向量计算单元706计算相邻且被指定的码字相同的多个特征向量中除  		  	 
                <br />去至少一个距离最远的特征向量剩余的特征向量的平均向量，来代替上述	 	 	 	 
                <br />相邻且码字相同的多个特征向量。 	    	 
                <br /></p>
      <p id="p-0096-zh" num="0096">可替代地，上述向量合并单元705也可以从相邻且码字相同的多个特	 	 	 	 
                <br />征向量中随机选择一个代表向量来代替上述相邻且码字相同的多个特征向 	    	 
                <br />量。 		 	 	 
                <br /></p>
      <p id="p-0097-zh" num="0097">可替代地，上述向量合并单元705也可以从相邻且码字相同的多个特 		 	 	 
                <br />征向量中选择与码本中该码字对应的特征向量最接近的特征向量来代替上  		  	 
                <br />述相邻且码字相同的多个特征向量。	 	 	 	 
                <br /></p>
      <p id="p-0098-zh" num="0098">可替代地，上述向量合并单元705也可以用码本中与该码字对应的特  		  	 
                <br />征向量代替上述相邻且码字相同的多个特征向量。	 	 	 	 
                <br /></p>
      <p id="p-0099-zh" num="0099">另外，根据本实施例的一个变形例，说话人模板的压缩装置700还可  		  	 
                <br />以包括：背景模板生成单元(background template generator)，其将压缩	 	 	 	 
                <br />后的说话人模板中的特征向量对应的码字序列保存为背景模板。 	    	 
                <br /></p>
      <p id="p-0100-zh" num="0100">本实施例的说话人模板的压缩装置700及其各个组成部分，可以由专	 	 	 	 
                <br />用的电路或芯片构成，也可以通过计算机(处理器)执行相应的程序来实 	    	 
                <br />现。并且，本实施例的说话人模板的压缩装置700，操作上可以实现前面 		 	 	 
                <br />实施例的说话人模板的压缩方法。  		  	 
                <br /></p>
      <p id="p-0101-zh" num="0101">在同一发明构思下，图8是根据本发明一个实施例的将多个说话人模 		 	 	 
                <br />板合并的装置的方框图。下面就结合该图，对本实施例进行描述。对于那  		  	 
                <br />些与前面实施例相同的部分，适当省略其说明。	 	 	 	 
                <br /></p>
      <p id="p-0102-zh" num="0102">如图8所示，本实施例的将多个说话人模板合并的装置800，包括：  		  	 
                <br />说话人模板的压缩装置700，其可以是前面结合图7描述的实施例的说话	 	 	 	 
                <br />人模板的压缩装置；以及DTW合并装置(DTW merging unit)801，用于 	    	 
                <br />对两个说话人模板进行DTW合并，如前面所述，可以采用现有的DTW 		 	 	 
                <br />合并方法，将两个说话人模板合并。  		  	 
                <br /></p>
      <p id="p-0103-zh" num="0103">本实施例的将多个说话人模板合并的装置800及其各个组成部分，可 		 	 	 
                <br />以由专用的电路或芯片构成，也可以通过计算机(处理器)执行相应的程  		  	 
                <br />序来实现。并且，本实施例的将多个说话人模板合并的装置800，操作上	 	 	 	 
                <br />可以实现前面结合图3A～3C描述的实施例的将多个说话人模板合并的方 	    	 
                <br />法。 		 	 	 
                <br /></p>
      <p id="p-0104-zh" num="0104">在同一发明构思下，图9是根据本发明一个实施例的说话人认证的注 	    	 
                <br />册装置的方框图。下面就结合该图，对本实施例进行描述。对于那些与前 		 	 	 
                <br />面实施例相同的部分，适当省略其说明。  		  	 
                <br /></p>
      <p id="p-0105-zh" num="0105">如图9所示，本实施例的说话人认证的注册装置900，包括：模板生  		  	 
                <br />成装置(template generator)901，用于根据说话人输入的语音生成说话	 	 	 	 
                <br />人模板，如前面所述，可以采用以往的生成模板方式，例如，采样提取语 	    	 
                <br />音中的声学特征，根据提取出的声学特征形成说话人模板；以及说话人模 		 	 	 
                <br />板合并装置800，其可以是前面结合图7描述的实施例的将多个说话人模  		  	 
                <br />板合并的装置，用于将由模板生成装置901生成的多个说话人模板合并。	 	 	 	 
                <br /></p>
      <p id="p-0106-zh" num="0106">本实施例的说话人认证的注册装置900及其各个组成部分，可以由专  		  	 
                <br />用的电路或芯片构成，也可以通过计算机(处理器)执行相应的程序来实	 	 	 	 
                <br />现。并且，本实施例的说话人认证的注册装置900，操作上可以实现前面 	    	 
                <br />实施例的说话人认证的注册方法。 		 	 	 
                <br /></p>
      <p id="p-0107-zh" num="0107">在同一发明构思下，图10是根据本发明一个实施例的说话人认证的验 	    	 
                <br />证装置的方框图。下面就结合该图，对本实施例进行描述。对于那些与前 		 	 	 
                <br />面实施例相同的部分，适当省略其说明。  		  	 
                <br /></p>
      <p id="p-0108-zh" num="0108">如图10所示，本实施例的说话人认证的验证装置1000，包括：语音 		 	 	 
                <br />输入单元(utterance input unit)1001，用于输入语音；声学特征提取单元  		  	 
                <br />(acoustic feature extractor)1002，用于从上述输入的语音提取声学特征；	 	 	 	 
                <br />匹配得分计算单元(matching score calculator)1003，用于计算由声学特 	    	 
                <br />征提取单元1002提取出的声学特征与说话人模板1004的DTW匹配得分， 		 	 	 
                <br />其中，说话人模板1004是前面所述实施例的说话人模板的压缩方法生成  		  	 
                <br />的。本实施例的说话人认证的验证装置1000通过比较上述计算出的DTW	 	 	 	 
                <br />匹配得分和预先设定的分辨阈值，判断输入的语音是否为说话人本人说出 	    	 
                <br />的注册密码语音。 		 	 	 
                <br /></p>
      <p id="p-0109-zh" num="0109">本实施例的说话人认证的验证装置1000及其各个组成部分，可以由专 	    	 
                <br />用的电路或芯片构成，也可以通过计算机(处理器)执行相应的程序来实 		 	 	 
                <br />现。并且，本实施例的说话人认证的验证装置1000，操作上可以实现前面  		  	 
                <br />结合图4说明的实施例的说话人认证的验证方法。	 	 	 	 
                <br /></p>
      <p id="p-0110-zh" num="0110">图11是根据本发明的另一个实施例的说话人认证的验证装置的方框  		  	 
                <br />图。下面就结合该图，对本实施例进行描述。对于那些与前面实施例相同	 	 	 	 
                <br />的部分，适当省略其说明。 		 	 	 
                <br /></p>
      <p id="p-0111-zh" num="0111">如图11所示，与前面实施例相同，本实施例的说话人认证的验证装置 	    	 
                <br />1100包括语音输入单元1001和声学特征提取单元1002。与前面实施例的 		 	 	 
                <br />不同之处在于，本实施例除了使用前面实施例的说话人模板的压缩方法生  		  	 
                <br />成的说话人模板1004以外，还使用前面所述实施例的说话人模板的压缩方	 	 	 	 
                <br />法生成的背景模板1103。 	    	 
                <br /></p>
      <p id="p-0112-zh" num="0112">本实施例的说话人认证的验证装置1100还包括：匹配得分计算单元	 	 	 	 
                <br />(matching score calculator)1101，计算由声学特征提取单元1002提取出 	    	 
                <br />的声学特征与说话人模板1004的DTW匹配得分，并且计算由声学特征提 		 	 	 
                <br />取单元1002提取出的声学特征与背景模板1103的DTW匹配得分；以及  		  	 
                <br />归一化单元(normalizing unit)1102，其利用提取出的声学特征与背景模	 	 	 	 
                <br />板的DTW匹配得分，对提取出的声学特征与说话人模板的DTW匹配得 	    	 
                <br />分进行归一化。这样，本实施例的说话人认证的验证装置1100就可以比较 		 	 	 
                <br />上述归一化后的DTW匹配得分和一个阈值，判断输入的语音是否为说话  		  	 
                <br />人本人说出的注册密码语音。	 	 	 	 
                <br /></p>
      <p id="p-0113-zh" num="0113">可替代地，根据本实施例的一个变形例，匹配得分计算单元(matching  		  	 
                <br />score calculator)1101，也可以计算由声学特征提取单元1002提取出的声	 	 	 	 
                <br />学特征与说话人模板1004的DTW匹配得分，并且计算说话人模板1004 	    	 
                <br />与背景模板1103的DTW匹配得分。归一化单元(normalizing unit)1102， 		 	 	 
                <br />则利用说话人模板1004与背景模板1103的DTW匹配得分，对提取出的  		  	 
                <br />声学特征与说话人模板1004的DTW匹配得分进行归一化。这样，本变形	 	 	 	 
                <br />例的说话人认证的验证装置1100也可以比较上述归一化后的DTW匹配得 	    	 
                <br />分和一个阈值，判断输入的语音是否为说话人本人说出的注册密码语音。 		 	 	 
                <br /></p>
      <p id="p-0114-zh" num="0114">本实施例的说话人认证的验证装置1100及其各个组成部分，可以由专 	    	 
                <br />用的电路或芯片构成，也可以通过计算机(处理器)执行相应的程序来实 		 	 	 
                <br />现。并且，本实施例的说话人认证的验证装置1100，操作上可以实现前面  		  	 
                <br />结合图5和图6说明的实施例的说话人认证的验证方法。	 	 	 	 
                <br /></p>
      <p id="p-0115-zh" num="0115">在同一发明构思下，图12是根据本发明一个实施例的说话人认证系统  		  	 
                <br />的方框图。下面就结合该图，对本实施例进行描述。对于那些与前面实施 	    	 
                <br />例相同的部分，适当省略其说明。 		 	 	 
                <br /></p>
      <p id="p-0116-zh" num="0116">如图12所示，本实施例的说话人认证系统包括：注册装置900，其可 	    	 
                <br />以为前面实施例描述的说话人认证的注册装置；以及验证装置1100，其可 		 	 	 
                <br />以为前面实施例描述的说话人认证的验证装置。由注册装置900生成的说  		  	 
                <br />话人模板，通过任意的通信方式，例如，网络、内部信道、磁盘等记录媒	 	 	 	 
                <br />体等，传递给验证装置1100。 	    	 
                <br /></p>
      <p id="p-0117-zh" num="0117">这样，如果采用本实施例的说话人认证系统，由于说话人模板的数据	 	 	 	 
                <br />量大大减小，因此，验证时可以大大减少运算量和存储空间。进而，如果 	    	 
                <br />在验证装置1100中使用背景模板进行归一化，还可以进一步提高系统性能 		 	 	 
                <br /></p>
      <p id="p-0118-zh" num="0118">以上虽然通过一些示例性的实施例对本发明的说话人模板的压缩方法 	    	 
                <br />和装置、将多个说话人模板合并的方法和装置、说话人认证的注册方法和 		 	 	 
                <br />装置、说话人认证的验证方法和装置、以及说话人认证系统。进行了详细  		  	 
                <br />的描述，但是以上这些实施例并不是穷举的，本领域技术人员可以在本发	 	 	 	 
                <br />明的精神和范围内实现各种变化和修改。因此，本发明并不限于这些实施 	    	 
                <br />例，本发明的范围仅由所附权利要求为准。 		 	 	 
                <br /></p>
    </mode-for-invention>
  </description>
  <claims id="claims_chi" lang="chi" format="original" date-changed="20091225">
    <claim num="1">
      <claim-text>
        <claim-text>1.一种说话人模板的压缩方法，其中，该说话人模板包含多个特征 		 	 	 
                <br />向量，该方法包括：  		  	 
                <br /></claim-text>
        <claim-text>根据一个码本，为说话人模板中的每个上述特征向量指定一个码字， 		 	 	 
                <br />其中上述码本包含多个码字以及每个码字对应的特征向量；以及  		  	 
                <br /></claim-text>
        <claim-text>将上述说话人模板中相邻且被指定的码字相同的多个特征向量用一个 		 	 	 
                <br />特征向量代替。  		  	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="2">
      <claim-text>
        <claim-text>2.根据权利要求1所述的说话人模板的压缩方法，其中，上述为每	 	 	 	 
                <br />个上述特征向量指定一个码字的步骤包括： 	    	 
                <br /></claim-text>
        <claim-text>为说话人模板中的每个上述特征向量查找码本中与之最接近的特征向	 	 	 	 
                <br />量；以及 	    	 
                <br /></claim-text>
        <claim-text>将上述最接近的特征向量对应的码字指定给上述说话人模板中的该特	 	 	 	 
                <br />征向量。 	    	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="3">
      <claim-text>
        <claim-text>3.根据权利要求1-2的任意一项所述的说话人模板的压缩方法，其 		 	 	 
                <br />中，上述将相邻且被指定的码字相同的多个特征向量用一个特征向量代替  		  	 
                <br />的步骤包括：	 	 	 	 
                <br /></claim-text>
        <claim-text>计算上述相邻且码字相同的多个特征向量的平均向量；以及  		  	 
                <br /></claim-text>
        <claim-text>用上述计算的平均向量代替上述相邻且码字相同的多个特征向量。 		 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="4">
      <claim-text>
        <claim-text>4.根据权利要求1-2的任意一项所述的说话人模板的压缩方法，其  		  	 
                <br />中，上述将相邻且被指定的码字相同的多个特征向量用一个特征向量代替	 	 	 	 
                <br />的步骤包括： 	    	 
                <br /></claim-text>
        <claim-text>从上述相邻且码字相同的多个特征向量中随机选择一个代表向量；以	 	 	 	 
                <br />及 	    	 
                <br /></claim-text>
        <claim-text>用上述代表向量代替上述相邻且码字相同的多个特征向量。	 	 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="5">
      <claim-text>
        <claim-text>5.根据权利要求1-2的任意一项所述的说话人模板的压缩方法，其 	    	 
                <br />中，上述将相邻且被指定的码字相同的多个特征向量用一个特征向量代替 		 	 	 
                <br />的步骤包括：  		  	 
                <br /></claim-text>
        <claim-text>从上述相邻且码字相同的多个特征向量中选择与码本中该码字对应的  		  	 
                <br />特征向量最接近的特征向量作为代表向量；以及	 	 	 	 
                <br /></claim-text>
        <claim-text>用上述代表向量代替上述相邻且码字相同的多个特征向量。  		  	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="6">
      <claim-text>
        <claim-text>6.根据权利要求1-2的任意一项所述的说话人模板的压缩方法，其	 	 	 	 
                <br />中，上述将相邻且被指定的码字相同的多个特征向量用一个特征向量代替 	    	 
                <br />的步骤包括： 		 	 	 
                <br /></claim-text>
        <claim-text>用上述码本中与该码字对应的特征向量代替上述相邻且码字相同的多 	    	 
                <br />个特征向量。 		 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="7">
      <claim-text>
        <claim-text>7.根据权利要求1-2的任意一项所述的说话人模板的压缩方法，其  		  	 
                <br />中，上述将相邻且被指定的码字相同的多个特征向量用一个特征向量代替	 	 	 	 
                <br />的步骤包括： 	    	 
                <br /></claim-text>
        <claim-text>计算上述相邻且被指定的码字相同的多个特征向量的每一个和上述码	 	 	 	 
                <br />本中与该码字对应的特征向量的距离； 	    	 
                <br /></claim-text>
        <claim-text>计算上述相邻且码字相同的多个特征向量中除去至少一个上述计算出	 	 	 	 
                <br />的距离最远的特征向量剩余的特征向量的平均向量；以及 	    	 
                <br /></claim-text>
        <claim-text>用上述计算的平均向量代替上述相邻且码字相同的多个特征向量。	 	 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="8">
      <claim-text>
        <claim-text>8.根据前面任意一项权利要求所述的说话人模板的压缩方法，进一 	    	 
                <br />步包括： 		 	 	 
                <br /></claim-text>
        <claim-text>将压缩后的上述说话人模板中的特征向量对应的码字序列保存为背景 	    	 
                <br />模板。 		 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="9">
      <claim-text>
        <claim-text>9.一种将多个说话人模板合并的方法，包括：  		  	 
                <br /></claim-text>
        <claim-text>利用权利要求1～8任意一项所述的说话人模板的压缩方法，分别对上 		 	 	 
                <br />述多个说话人模板进行压缩；以及  		  	 
                <br /></claim-text>
        <claim-text>对上述压缩后的多个说话人模板进行DTW合并。 		 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="10">
      <claim-text>
        <claim-text>10.一种将多个说话人模板合并的方法，包括：  		  	 
                <br /></claim-text>
        <claim-text>对上述多个说话人模板进行DTW合并，形成一个单独模板；以及 		 	 	 
                <br /></claim-text>
        <claim-text>利用权利要求1～8任意一项所述的说话人模板的压缩方法，对上述合 	    	 
                <br />并后的说话人模板进行压缩。 		 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="11">
      <claim-text>
        <claim-text>11.一种将多个说话人模板合并的方法，包括：	 	 	 	 
                <br /></claim-text>
        <claim-text>利用权利要求1～8任意一项所述的说话人模板的压缩方法，对上述多  		  	 
                <br />个说话人模板中的至少一个说话人模板进行压缩；以及	 	 	 	 
                <br /></claim-text>
        <claim-text>将上述压缩后的至少一个说话人模板与其它的说话人模板DTW合  		  	 
                <br />并。	 	 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="12">
      <claim-text>
        <claim-text>12.一种说话人认证的注册方法，包括： 	    	 
                <br /></claim-text>
        <claim-text>根据说话人输入的多个语音生成多个说话人模板；以及	 	 	 	 
                <br /></claim-text>
        <claim-text>利用权利要求9～11任意一项所述的将多个说话人模板合并的方法，  		  	 
                <br />将上述生成的多个说话人模板合并。	 	 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="13">
      <claim-text>
        <claim-text>13.一种说话人认证的验证方法，包括： 	    	 
                <br /></claim-text>
        <claim-text>输入语音；以及	 	 	 	 
                <br /></claim-text>
        <claim-text>根据说话人模板，判断该输入的语音是否为说话人本人说出的注册密  		  	 
                <br />码语音，其中，上述说话人模板是利用权利要求1～8任意一项所述的说话	 	 	 	 
                <br />人模板的压缩方法生成的。 	    	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="14">
      <claim-text>
        <claim-text>14.根据权利要求13所述的说话人认证的验证方法，其中，判断该 		 	 	 
                <br />输入的语音是否为说话人本人说出的注册密码语音的步骤包括：  		  	 
                <br /></claim-text>
        <claim-text>从上述输入的语音提取声学特征； 		 	 	 
                <br /></claim-text>
        <claim-text>计算上述提取出的声学特征与上述说话人模板的DTW匹配得分；以 	    	 
                <br />及 		 	 	 
                <br /></claim-text>
        <claim-text>比较上述计算出的DTW匹配得分和一个阈值，判断输入的语音是否 	    	 
                <br />为说话人本人说出的注册密码语音。 		 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="15">
      <claim-text>
        <claim-text>15.一种说话人认证的验证方法，包括：  		  	 
                <br /></claim-text>
        <claim-text>输入语音；以及 		 	 	 
                <br /></claim-text>
        <claim-text>根据说话人模板和背景模板，判断该输入的语音是否为说话人本人说 	    	 
                <br />出的注册密码语音，其中，上述说话人模板和背景模板是利用权利要求8 		 	 	 
                <br />所述的说话人模板的压缩方法生成的。  		  	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="16">
      <claim-text>
        <claim-text>16.根据权利要求15所述的说话人认证的验证方法，其中，判断该	 	 	 	 
                <br />输入的语音是否为说话人本人说出的注册密码语音的步骤包括： 	    	 
                <br /></claim-text>
        <claim-text>从上述输入的语音提取声学特征； 	    	 
                <br /></claim-text>
        <claim-text>计算上述提取出的声学特征与上述说话人模板的DTW匹配得分；	 	 	 	 
                <br /></claim-text>
        <claim-text>计算上述提取出的声学特征与上述背景模板的DTW匹配得分；  		  	 
                <br /></claim-text>
        <claim-text>利用上述提取出的声学特征与上述背景模板的DTW匹配得分，对上 		 	 	 
                <br />述提取出的声学特征与上述说话人模板的DTW匹配得分进行归一化；以  		  	 
                <br />及	 	 	 	 
                <br /></claim-text>
        <claim-text>比较上述归一化后的DTW匹配得分和一个阈值，判断输入的语音是  		  	 
                <br />否为说话人本人说出的注册密码语音。	 	 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="17">
      <claim-text>
        <claim-text>17.根据权利要求15所述的说话人认证的验证方法，其中，判断该 	    	 
                <br />输入的语音是否为说话人本人说出的注册密码语音的步骤包括： 		 	 	 
                <br /></claim-text>
        <claim-text>从上述输入的语音提取声学特征； 	    	 
                <br /></claim-text>
        <claim-text>计算上述提取出的声学特征与上述说话人模板的DTW匹配得分；	 	 	 	 
                <br /></claim-text>
        <claim-text>计算上述说话人模板与上述背景模板的DTW匹配得分；  		  	 
                <br /></claim-text>
        <claim-text>利用上述说话人模板与上述背景模板的DTW匹配得分，对上述提取 		 	 	 
                <br />出的声学特征与上述说话人模板的DTW匹配得分进行归一化；以及  		  	 
                <br /></claim-text>
        <claim-text>比较上述归一化后的DTW匹配得分和一个阈值，判断输入的语音是 		 	 	 
                <br />否为说话人本人说出的注册密码语音。  		  	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="18">
      <claim-text>
        <claim-text>18.一种说话人模板的压缩装置，其中，该说话人模板包含多个特征	 	 	 	 
                <br />向量，包括： 	    	 
                <br /></claim-text>
        <claim-text>码字指定单元(code designating unit)，其根据一个码本为说话人模	 	 	 	 
                <br />板中的每个上述特征向量指定一个码字，其中上述码本包含多个码字以及 	    	 
                <br />每个码字对应的特征向量；以及 		 	 	 
                <br /></claim-text>
        <claim-text>向量合并单元(vector merging unit)，其将上述说话人模板中相邻且 	    	 
                <br />被指定的码字相同的多个特征向量用一个特征向量代替。 		 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="19">
      <claim-text>
        <claim-text>19.根据权利要求18所述的说话人模板的压缩装置，进一步包括：  		  	 
                <br /></claim-text>
        <claim-text>向量距离计算单元(vector distance calculator)，用于计算两个向量 		 	 	 
                <br />之间的距离；以及  		  	 
                <br /></claim-text>
        <claim-text>码字查找单元(code search unit)，其利用上述向量距离计算单元， 		 	 	 
                <br />在码本中查找与一个给定的特征向量最接近的特征向量及其对应的码字。	 	 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="20">
      <claim-text>
        <claim-text>20.根据权利要求18-19的任意一项所述的说话人模板的压缩装置， 	    	 
                <br />进一步包括： 		 	 	 
                <br /></claim-text>
        <claim-text>平均向量计算单元(average vector calculator)，用于计算多个特征 	    	 
                <br />向量的平均向量。 		 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="21">
      <claim-text>
        <claim-text>21.根据权利要求20所述的说话人模板的压缩装置，其中，上述向  		  	 
                <br />量合并单元，用上述平均向量计算单元计算的上述相邻且码字相同的多个	 	 	 	 
                <br />特征向量的平均向量代替上述相邻且码字相同的多个特征向量。 	    	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="22">
      <claim-text>
        <claim-text>22.根据权利要求20所述的说话人模板的压缩装置，上述向量合并 		 	 	 
                <br />单元，用上述平均向量计算单元计算的上述相邻且被指定的码字相同的多  		  	 
                <br />个特征向量中除去至少一个距离最远的特征向量剩余的特征向量的平均向	 	 	 	 
                <br />量代替上述相邻且码字相同的多个特征向量。 	    	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="23">
      <claim-text>
        <claim-text>23.根据权利要求18-19的任意一项所述的说话人模板的压缩装置， 		 	 	 
                <br />其中，上述向量合并单元，从上述相邻且码字相同的多个特征向量中随机  		  	 
                <br />选择一个代表向量来代替上述相邻且码字相同的多个特征向量。	 	 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="24">
      <claim-text>
        <claim-text>24.根据权利要求18-19的任意一项所述的说话人模板的压缩装置， 	    	 
                <br />其中，上述向量合并单元，从上述相邻且码字相同的多个特征向量中选择 		 	 	 
                <br />与码本中该码字对应的特征向量最接近的特征向量来代替上述相邻且码字  		  	 
                <br />相同的多个特征向量。	 	 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="25">
      <claim-text>
        <claim-text>25.根据权利要求18-19的任意一项所述的说话人模板的压缩装置， 	    	 
                <br />其中，上述向量合并单元，用上述码本中与该码字对应的特征向量代替上 		 	 	 
                <br />述相邻且码字相同的多个特征向量。  		  	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="26">
      <claim-text>
        <claim-text>26.根据权利要求18-25的任意一项所述的说话人模板的压缩装置，	 	 	 	 
                <br />进一步包括： 	    	 
                <br /></claim-text>
        <claim-text>背景模板生成单元(background template generator)，其将压缩后的	 	 	 	 
                <br />上述说话人模板中的特征向量对应的码字序列保存为背景模板。 	    	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="27">
      <claim-text>
        <claim-text>27.一种将多个说话人模板合并的装置，包括： 		 	 	 
                <br /></claim-text>
        <claim-text>根据权利要求18～26的任意一项所述的说话人模板的压缩装置；以及 	    	 
                <br /></claim-text>
        <claim-text>DTW合并装置(DTW merging unit)，用于对两个说话人模板进行 	    	 
                <br />DTW合并。 		 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="28">
      <claim-text>
        <claim-text>28.一种说话人认证的注册装置，包括：  		  	 
                <br /></claim-text>
        <claim-text>模板生成装置(template generator)，用于根据说话人输入的语音生 		 	 	 
                <br />成说话人模板；以及  		  	 
                <br /></claim-text>
        <claim-text>根据权利要求27所述的将多个说话人模板合并的装置，将由上述模板 		 	 	 
                <br />生成装置生成的多个说话人模板合并。  		  	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="29">
      <claim-text>
        <claim-text>29.一种说话人认证的验证装置，包括：	 	 	 	 
                <br /></claim-text>
        <claim-text>语音输入单元(utterance input unit)，用于输入语音；  		  	 
                <br /></claim-text>
        <claim-text>声学特征提取单元(acoustic feature extractor)，用于从上述输入的语 		 	 	 
                <br />音提取声学特征；以及  		  	 
                <br /></claim-text>
        <claim-text>匹配得分计算单元(matching score calculator)，用于计算上述提取 		 	 	 
                <br />出的声学特征与相应的说话人模板的DTW匹配得分，其中，上述说话人  		  	 
                <br />模板是利用权利要求1～8的任意一项所述的说话人模板的压缩方法生成	 	 	 	 
                <br />的； 	    	 
                <br /></claim-text>
        <claim-text>其中，通过比较上述计算出的DTW匹配得分和预先设定的分辨阈值，	 	 	 	 
                <br />判断输入的语音是否为说话人本人说出的注册密码语音。 	    	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="30">
      <claim-text>
        <claim-text>30.一种说话人认证的验证装置，包括： 		 	 	 
                <br /></claim-text>
        <claim-text>语音输入单元(utterance input unit)，用于输入语音； 	    	 
                <br /></claim-text>
        <claim-text>声学特征提取单元(acoustic feature extractor)，用于从上述输入的语	 	 	 	 
                <br />音提取声学特征； 	    	 
                <br /></claim-text>
        <claim-text>匹配得分计算单元(matching score calculator)，计算上述提取出的	 	 	 	 
                <br />声学特征与说话人模板的DTW匹配得分，以及计算上述提取出的声学特 	    	 
                <br />征与背景模板的DTW匹配得分，其中上述说话人模板和背景模板是利用 		 	 	 
                <br />权利要求8所述的说话人模板的压缩方法生成的；以及  		  	 
                <br /></claim-text>
        <claim-text>归一化单元(normalizing unit)，其利用上述提取出的声学特征与上 		 	 	 
                <br />述背景模板的DTW匹配得分，对上述提取出的声学特征与上述说话人模  		  	 
                <br />板的DTW匹配得分进行归一化；	 	 	 	 
                <br /></claim-text>
        <claim-text>其中，比较上述归一化后的DTW匹配得分和一个阈值，判断输入的	 	 	 	 
                <br />语音是否为说话人本人说出的注册密码语音。 	    	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="31">
      <claim-text>
        <claim-text>31.一种说话人认证的验证装置，包括： 		 	 	 
                <br /></claim-text>
        <claim-text>语音输入单元(utterance input unit)，用于输入语音； 	    	 
                <br /></claim-text>
        <claim-text>声学特征提取单元(acoustic feature extractor)，用于从上述输入的语	 	 	 	 
                <br />音提取声学特征； 	    	 
                <br /></claim-text>
        <claim-text>匹配得分计算单元(matching score calculator)，用于计算上述提取	 	 	 	 
                <br />出的声学特征与说话人模板的DTW匹配得分，以及计算上述说话人模板 	    	 
                <br />与背景模板的DTW匹配得分；其中上述说话人模板和背景模板是利用权 		 	 	 
                <br />利要求8所述的说话人模板的压缩方法生成的；以及  		  	 
                <br /></claim-text>
        <claim-text>归一化单元(normalizing unit)，其利用上述说话人模板与上述背景 		 	 	 
                <br />模板的DTW匹配得分，对上述提取出的声学特征与上述说话人模板的  		  	 
                <br />DTW匹配得分进行归一化；	 	 	 	 
                <br /></claim-text>
        <claim-text>其中，比较上述归一化后的DTW匹配得分和一个阈值，判断输入的  		  	 
                <br />语音是否为说话人本人说出的注册密码语音。	 	 	 	 
                <br /></claim-text>
      </claim-text>
    </claim>
    <claim num="32">
      <claim-text>
        <claim-text>32.一种说话人认证系统，包括： 	    	 
                <br /></claim-text>
        <claim-text>根据权利要求28所述的说话人认证的注册装置；以及	 	 	 	 
                <br /></claim-text>
        <claim-text>根据权利要求29～31的任意一项所述的说话人认证的验证装置。  		  	 
                <br /></claim-text>
      </claim-text>
    </claim>
  </claims>
</lexisnexis-patent-document>